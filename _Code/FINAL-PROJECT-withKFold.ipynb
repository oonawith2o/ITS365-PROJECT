{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2cd365f8",
   "metadata": {},
   "source": [
    "# FINAL PROJECT ITS365 by Abbie McDowell and Oona Kintscher"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f964f81",
   "metadata": {},
   "source": [
    "Goal: Predict NBA players win shares for their age 25 season based on their rookie years statistics."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "335a8629",
   "metadata": {},
   "source": [
    "## Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f65258e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sb\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_selection import f_regression, VarianceThreshold\n",
    "from sklearn.metrics import mean_absolute_error, r2_score\n",
    "\n",
    "from keras.layers import Normalization, Dense, Dropout\n",
    "from keras.optimizers import Adam\n",
    "from keras.models import Sequential\n",
    "from keras import regularizers\n",
    "\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras import backend as K\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47a4b945",
   "metadata": {},
   "source": [
    "## Import Data from .csv File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7ac8fa70",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df = pd.read_csv(r'365finalproject.csv', encoding= 'unicode_escape')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "349bee6f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PlayerID</th>\n",
       "      <th>Player</th>\n",
       "      <th>Age</th>\n",
       "      <th>Games</th>\n",
       "      <th>Minutes</th>\n",
       "      <th>FGM</th>\n",
       "      <th>FGA</th>\n",
       "      <th>3PM</th>\n",
       "      <th>3PA</th>\n",
       "      <th>FTM</th>\n",
       "      <th>...</th>\n",
       "      <th>PF</th>\n",
       "      <th>PTS</th>\n",
       "      <th>FG%</th>\n",
       "      <th>3P%</th>\n",
       "      <th>FT%</th>\n",
       "      <th>MPG</th>\n",
       "      <th>PPG</th>\n",
       "      <th>RPG</th>\n",
       "      <th>APG</th>\n",
       "      <th>WS_25</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>duartch01</td>\n",
       "      <td>Chris Duarte</td>\n",
       "      <td>24</td>\n",
       "      <td>55</td>\n",
       "      <td>1541</td>\n",
       "      <td>268</td>\n",
       "      <td>621</td>\n",
       "      <td>94</td>\n",
       "      <td>255</td>\n",
       "      <td>90</td>\n",
       "      <td>...</td>\n",
       "      <td>95</td>\n",
       "      <td>720</td>\n",
       "      <td>0.432</td>\n",
       "      <td>0.369</td>\n",
       "      <td>0.804</td>\n",
       "      <td>28.0</td>\n",
       "      <td>13.1</td>\n",
       "      <td>4.1</td>\n",
       "      <td>2.1</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>marshna01</td>\n",
       "      <td>Naji Marshall</td>\n",
       "      <td>23</td>\n",
       "      <td>32</td>\n",
       "      <td>700</td>\n",
       "      <td>82</td>\n",
       "      <td>209</td>\n",
       "      <td>29</td>\n",
       "      <td>83</td>\n",
       "      <td>53</td>\n",
       "      <td>...</td>\n",
       "      <td>58</td>\n",
       "      <td>246</td>\n",
       "      <td>0.392</td>\n",
       "      <td>0.349</td>\n",
       "      <td>0.707</td>\n",
       "      <td>21.9</td>\n",
       "      <td>7.7</td>\n",
       "      <td>4.6</td>\n",
       "      <td>2.8</td>\n",
       "      <td>2.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>pritcpa01</td>\n",
       "      <td>Payton Pritchard</td>\n",
       "      <td>23</td>\n",
       "      <td>66</td>\n",
       "      <td>1268</td>\n",
       "      <td>184</td>\n",
       "      <td>418</td>\n",
       "      <td>102</td>\n",
       "      <td>248</td>\n",
       "      <td>40</td>\n",
       "      <td>...</td>\n",
       "      <td>104</td>\n",
       "      <td>510</td>\n",
       "      <td>0.440</td>\n",
       "      <td>0.411</td>\n",
       "      <td>0.889</td>\n",
       "      <td>19.2</td>\n",
       "      <td>7.7</td>\n",
       "      <td>2.4</td>\n",
       "      <td>1.8</td>\n",
       "      <td>0.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>windldy01</td>\n",
       "      <td>Dylan Windler</td>\n",
       "      <td>24</td>\n",
       "      <td>31</td>\n",
       "      <td>513</td>\n",
       "      <td>57</td>\n",
       "      <td>130</td>\n",
       "      <td>26</td>\n",
       "      <td>77</td>\n",
       "      <td>21</td>\n",
       "      <td>...</td>\n",
       "      <td>37</td>\n",
       "      <td>161</td>\n",
       "      <td>0.438</td>\n",
       "      <td>0.338</td>\n",
       "      <td>0.778</td>\n",
       "      <td>16.5</td>\n",
       "      <td>5.2</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.1</td>\n",
       "      <td>0.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>clarkbr01</td>\n",
       "      <td>Brandon Clarke</td>\n",
       "      <td>23</td>\n",
       "      <td>58</td>\n",
       "      <td>1300</td>\n",
       "      <td>296</td>\n",
       "      <td>479</td>\n",
       "      <td>23</td>\n",
       "      <td>64</td>\n",
       "      <td>85</td>\n",
       "      <td>...</td>\n",
       "      <td>100</td>\n",
       "      <td>700</td>\n",
       "      <td>0.618</td>\n",
       "      <td>0.359</td>\n",
       "      <td>0.759</td>\n",
       "      <td>22.4</td>\n",
       "      <td>12.1</td>\n",
       "      <td>5.9</td>\n",
       "      <td>1.4</td>\n",
       "      <td>6.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1031</th>\n",
       "      <td>kunneke01</td>\n",
       "      <td>Kevin Kunnert</td>\n",
       "      <td>22</td>\n",
       "      <td>64</td>\n",
       "      <td>701</td>\n",
       "      <td>105</td>\n",
       "      <td>215</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>21</td>\n",
       "      <td>...</td>\n",
       "      <td>151</td>\n",
       "      <td>231</td>\n",
       "      <td>0.488</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.636</td>\n",
       "      <td>11.0</td>\n",
       "      <td>3.6</td>\n",
       "      <td>3.4</td>\n",
       "      <td>0.7</td>\n",
       "      <td>4.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1032</th>\n",
       "      <td>mcneila01</td>\n",
       "      <td>Larry McNeill</td>\n",
       "      <td>23</td>\n",
       "      <td>54</td>\n",
       "      <td>516</td>\n",
       "      <td>106</td>\n",
       "      <td>220</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>99</td>\n",
       "      <td>...</td>\n",
       "      <td>76</td>\n",
       "      <td>311</td>\n",
       "      <td>0.482</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.707</td>\n",
       "      <td>9.6</td>\n",
       "      <td>5.8</td>\n",
       "      <td>2.7</td>\n",
       "      <td>0.4</td>\n",
       "      <td>4.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1033</th>\n",
       "      <td>ratleed01</td>\n",
       "      <td>Ed Ratleff</td>\n",
       "      <td>23</td>\n",
       "      <td>81</td>\n",
       "      <td>1773</td>\n",
       "      <td>254</td>\n",
       "      <td>585</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>103</td>\n",
       "      <td>...</td>\n",
       "      <td>182</td>\n",
       "      <td>611</td>\n",
       "      <td>0.434</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.798</td>\n",
       "      <td>21.9</td>\n",
       "      <td>7.5</td>\n",
       "      <td>3.5</td>\n",
       "      <td>2.2</td>\n",
       "      <td>4.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1034</th>\n",
       "      <td>wattssl01</td>\n",
       "      <td>Slick Watts</td>\n",
       "      <td>22</td>\n",
       "      <td>62</td>\n",
       "      <td>1424</td>\n",
       "      <td>198</td>\n",
       "      <td>510</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>100</td>\n",
       "      <td>...</td>\n",
       "      <td>207</td>\n",
       "      <td>496</td>\n",
       "      <td>0.388</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.645</td>\n",
       "      <td>23.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>2.9</td>\n",
       "      <td>5.7</td>\n",
       "      <td>3.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1035</th>\n",
       "      <td>weathni01</td>\n",
       "      <td>Nick Weatherspoon</td>\n",
       "      <td>23</td>\n",
       "      <td>65</td>\n",
       "      <td>1216</td>\n",
       "      <td>199</td>\n",
       "      <td>483</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>96</td>\n",
       "      <td>...</td>\n",
       "      <td>179</td>\n",
       "      <td>494</td>\n",
       "      <td>0.412</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.691</td>\n",
       "      <td>18.7</td>\n",
       "      <td>7.6</td>\n",
       "      <td>6.1</td>\n",
       "      <td>0.6</td>\n",
       "      <td>2.4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1036 rows × 26 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       PlayerID             Player  Age  Games  Minutes  FGM  FGA  3PM  3PA  \\\n",
       "0     duartch01       Chris Duarte   24     55     1541  268  621   94  255   \n",
       "1     marshna01      Naji Marshall   23     32      700   82  209   29   83   \n",
       "2     pritcpa01   Payton Pritchard   23     66     1268  184  418  102  248   \n",
       "3     windldy01      Dylan Windler   24     31      513   57  130   26   77   \n",
       "4     clarkbr01     Brandon Clarke   23     58     1300  296  479   23   64   \n",
       "...         ...                ...  ...    ...      ...  ...  ...  ...  ...   \n",
       "1031  kunneke01      Kevin Kunnert   22     64      701  105  215    0    0   \n",
       "1032  mcneila01      Larry McNeill   23     54      516  106  220    0    0   \n",
       "1033  ratleed01         Ed Ratleff   23     81     1773  254  585    0    0   \n",
       "1034  wattssl01        Slick Watts   22     62     1424  198  510    0    0   \n",
       "1035  weathni01  Nick Weatherspoon   23     65     1216  199  483    0    0   \n",
       "\n",
       "      FTM  ...   PF  PTS    FG%    3P%    FT%   MPG   PPG  RPG  APG  WS_25  \n",
       "0      90  ...   95  720  0.432  0.369  0.804  28.0  13.1  4.1  2.1    0.0  \n",
       "1      53  ...   58  246  0.392  0.349  0.707  21.9   7.7  4.6  2.8    2.5  \n",
       "2      40  ...  104  510  0.440  0.411  0.889  19.2   7.7  2.4  1.8    0.6  \n",
       "3      21  ...   37  161  0.438  0.338  0.778  16.5   5.2  3.5  1.1    0.8  \n",
       "4      85  ...  100  700  0.618  0.359  0.759  22.4  12.1  5.9  1.4    6.3  \n",
       "...   ...  ...  ...  ...    ...    ...    ...   ...   ...  ...  ...    ...  \n",
       "1031   21  ...  151  231  0.488  0.000  0.636  11.0   3.6  3.4  0.7    4.1  \n",
       "1032   99  ...   76  311  0.482  0.000  0.707   9.6   5.8  2.7  0.4    4.3  \n",
       "1033  103  ...  182  611  0.434  0.000  0.798  21.9   7.5  3.5  2.2    4.5  \n",
       "1034  100  ...  207  496  0.388  0.000  0.645  23.0   8.0  2.9  5.7    3.3  \n",
       "1035   96  ...  179  494  0.412  0.000  0.691  18.7   7.6  6.1  0.6    2.4  \n",
       "\n",
       "[1036 rows x 26 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f2e6264f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "names_ds = df[[\"PlayerID\", \"Player\"]]\n",
    "features_ds_raw = df.loc[:,'Age':'APG']\n",
    "features_ds_raw = features_ds_raw.drop([\"3PM\", \"3PA\", \"3P%\"], axis=1)\n",
    "labels_ds_raw = df[[\"WS_25\"]]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f594ba81",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PlayerID</th>\n",
       "      <th>Player</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>duartch01</td>\n",
       "      <td>Chris Duarte</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>marshna01</td>\n",
       "      <td>Naji Marshall</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>pritcpa01</td>\n",
       "      <td>Payton Pritchard</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>windldy01</td>\n",
       "      <td>Dylan Windler</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>clarkbr01</td>\n",
       "      <td>Brandon Clarke</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1031</th>\n",
       "      <td>kunneke01</td>\n",
       "      <td>Kevin Kunnert</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1032</th>\n",
       "      <td>mcneila01</td>\n",
       "      <td>Larry McNeill</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1033</th>\n",
       "      <td>ratleed01</td>\n",
       "      <td>Ed Ratleff</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1034</th>\n",
       "      <td>wattssl01</td>\n",
       "      <td>Slick Watts</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1035</th>\n",
       "      <td>weathni01</td>\n",
       "      <td>Nick Weatherspoon</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1036 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       PlayerID             Player\n",
       "0     duartch01       Chris Duarte\n",
       "1     marshna01      Naji Marshall\n",
       "2     pritcpa01   Payton Pritchard\n",
       "3     windldy01      Dylan Windler\n",
       "4     clarkbr01     Brandon Clarke\n",
       "...         ...                ...\n",
       "1031  kunneke01      Kevin Kunnert\n",
       "1032  mcneila01      Larry McNeill\n",
       "1033  ratleed01         Ed Ratleff\n",
       "1034  wattssl01        Slick Watts\n",
       "1035  weathni01  Nick Weatherspoon\n",
       "\n",
       "[1036 rows x 2 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "names_ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9945803d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Age</th>\n",
       "      <th>Games</th>\n",
       "      <th>Minutes</th>\n",
       "      <th>FGM</th>\n",
       "      <th>FGA</th>\n",
       "      <th>FTM</th>\n",
       "      <th>FTA</th>\n",
       "      <th>ORB</th>\n",
       "      <th>TRB</th>\n",
       "      <th>AST</th>\n",
       "      <th>STL</th>\n",
       "      <th>BLK</th>\n",
       "      <th>PF</th>\n",
       "      <th>PTS</th>\n",
       "      <th>FG%</th>\n",
       "      <th>FT%</th>\n",
       "      <th>MPG</th>\n",
       "      <th>PPG</th>\n",
       "      <th>RPG</th>\n",
       "      <th>APG</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>24</td>\n",
       "      <td>55</td>\n",
       "      <td>1541</td>\n",
       "      <td>268</td>\n",
       "      <td>621</td>\n",
       "      <td>90</td>\n",
       "      <td>112</td>\n",
       "      <td>41</td>\n",
       "      <td>226</td>\n",
       "      <td>114</td>\n",
       "      <td>56</td>\n",
       "      <td>10</td>\n",
       "      <td>95</td>\n",
       "      <td>720</td>\n",
       "      <td>0.432</td>\n",
       "      <td>0.804</td>\n",
       "      <td>28.0</td>\n",
       "      <td>13.1</td>\n",
       "      <td>4.1</td>\n",
       "      <td>2.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>23</td>\n",
       "      <td>32</td>\n",
       "      <td>700</td>\n",
       "      <td>82</td>\n",
       "      <td>209</td>\n",
       "      <td>53</td>\n",
       "      <td>75</td>\n",
       "      <td>15</td>\n",
       "      <td>148</td>\n",
       "      <td>88</td>\n",
       "      <td>26</td>\n",
       "      <td>10</td>\n",
       "      <td>58</td>\n",
       "      <td>246</td>\n",
       "      <td>0.392</td>\n",
       "      <td>0.707</td>\n",
       "      <td>21.9</td>\n",
       "      <td>7.7</td>\n",
       "      <td>4.6</td>\n",
       "      <td>2.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>23</td>\n",
       "      <td>66</td>\n",
       "      <td>1268</td>\n",
       "      <td>184</td>\n",
       "      <td>418</td>\n",
       "      <td>40</td>\n",
       "      <td>45</td>\n",
       "      <td>33</td>\n",
       "      <td>158</td>\n",
       "      <td>120</td>\n",
       "      <td>37</td>\n",
       "      <td>9</td>\n",
       "      <td>104</td>\n",
       "      <td>510</td>\n",
       "      <td>0.440</td>\n",
       "      <td>0.889</td>\n",
       "      <td>19.2</td>\n",
       "      <td>7.7</td>\n",
       "      <td>2.4</td>\n",
       "      <td>1.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>24</td>\n",
       "      <td>31</td>\n",
       "      <td>513</td>\n",
       "      <td>57</td>\n",
       "      <td>130</td>\n",
       "      <td>21</td>\n",
       "      <td>27</td>\n",
       "      <td>20</td>\n",
       "      <td>107</td>\n",
       "      <td>33</td>\n",
       "      <td>19</td>\n",
       "      <td>12</td>\n",
       "      <td>37</td>\n",
       "      <td>161</td>\n",
       "      <td>0.438</td>\n",
       "      <td>0.778</td>\n",
       "      <td>16.5</td>\n",
       "      <td>5.2</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>23</td>\n",
       "      <td>58</td>\n",
       "      <td>1300</td>\n",
       "      <td>296</td>\n",
       "      <td>479</td>\n",
       "      <td>85</td>\n",
       "      <td>112</td>\n",
       "      <td>92</td>\n",
       "      <td>345</td>\n",
       "      <td>81</td>\n",
       "      <td>32</td>\n",
       "      <td>48</td>\n",
       "      <td>100</td>\n",
       "      <td>700</td>\n",
       "      <td>0.618</td>\n",
       "      <td>0.759</td>\n",
       "      <td>22.4</td>\n",
       "      <td>12.1</td>\n",
       "      <td>5.9</td>\n",
       "      <td>1.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1031</th>\n",
       "      <td>22</td>\n",
       "      <td>64</td>\n",
       "      <td>701</td>\n",
       "      <td>105</td>\n",
       "      <td>215</td>\n",
       "      <td>21</td>\n",
       "      <td>33</td>\n",
       "      <td>83</td>\n",
       "      <td>217</td>\n",
       "      <td>43</td>\n",
       "      <td>10</td>\n",
       "      <td>54</td>\n",
       "      <td>151</td>\n",
       "      <td>231</td>\n",
       "      <td>0.488</td>\n",
       "      <td>0.636</td>\n",
       "      <td>11.0</td>\n",
       "      <td>3.6</td>\n",
       "      <td>3.4</td>\n",
       "      <td>0.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1032</th>\n",
       "      <td>23</td>\n",
       "      <td>54</td>\n",
       "      <td>516</td>\n",
       "      <td>106</td>\n",
       "      <td>220</td>\n",
       "      <td>99</td>\n",
       "      <td>140</td>\n",
       "      <td>60</td>\n",
       "      <td>146</td>\n",
       "      <td>24</td>\n",
       "      <td>35</td>\n",
       "      <td>6</td>\n",
       "      <td>76</td>\n",
       "      <td>311</td>\n",
       "      <td>0.482</td>\n",
       "      <td>0.707</td>\n",
       "      <td>9.6</td>\n",
       "      <td>5.8</td>\n",
       "      <td>2.7</td>\n",
       "      <td>0.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1033</th>\n",
       "      <td>23</td>\n",
       "      <td>81</td>\n",
       "      <td>1773</td>\n",
       "      <td>254</td>\n",
       "      <td>585</td>\n",
       "      <td>103</td>\n",
       "      <td>129</td>\n",
       "      <td>93</td>\n",
       "      <td>286</td>\n",
       "      <td>181</td>\n",
       "      <td>90</td>\n",
       "      <td>27</td>\n",
       "      <td>182</td>\n",
       "      <td>611</td>\n",
       "      <td>0.434</td>\n",
       "      <td>0.798</td>\n",
       "      <td>21.9</td>\n",
       "      <td>7.5</td>\n",
       "      <td>3.5</td>\n",
       "      <td>2.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1034</th>\n",
       "      <td>22</td>\n",
       "      <td>62</td>\n",
       "      <td>1424</td>\n",
       "      <td>198</td>\n",
       "      <td>510</td>\n",
       "      <td>100</td>\n",
       "      <td>155</td>\n",
       "      <td>72</td>\n",
       "      <td>182</td>\n",
       "      <td>351</td>\n",
       "      <td>115</td>\n",
       "      <td>13</td>\n",
       "      <td>207</td>\n",
       "      <td>496</td>\n",
       "      <td>0.388</td>\n",
       "      <td>0.645</td>\n",
       "      <td>23.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>2.9</td>\n",
       "      <td>5.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1035</th>\n",
       "      <td>23</td>\n",
       "      <td>65</td>\n",
       "      <td>1216</td>\n",
       "      <td>199</td>\n",
       "      <td>483</td>\n",
       "      <td>96</td>\n",
       "      <td>139</td>\n",
       "      <td>133</td>\n",
       "      <td>397</td>\n",
       "      <td>38</td>\n",
       "      <td>48</td>\n",
       "      <td>16</td>\n",
       "      <td>179</td>\n",
       "      <td>494</td>\n",
       "      <td>0.412</td>\n",
       "      <td>0.691</td>\n",
       "      <td>18.7</td>\n",
       "      <td>7.6</td>\n",
       "      <td>6.1</td>\n",
       "      <td>0.6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1036 rows × 20 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Age  Games  Minutes  FGM  FGA  FTM  FTA  ORB  TRB  AST  STL  BLK   PF  \\\n",
       "0      24     55     1541  268  621   90  112   41  226  114   56   10   95   \n",
       "1      23     32      700   82  209   53   75   15  148   88   26   10   58   \n",
       "2      23     66     1268  184  418   40   45   33  158  120   37    9  104   \n",
       "3      24     31      513   57  130   21   27   20  107   33   19   12   37   \n",
       "4      23     58     1300  296  479   85  112   92  345   81   32   48  100   \n",
       "...   ...    ...      ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...   \n",
       "1031   22     64      701  105  215   21   33   83  217   43   10   54  151   \n",
       "1032   23     54      516  106  220   99  140   60  146   24   35    6   76   \n",
       "1033   23     81     1773  254  585  103  129   93  286  181   90   27  182   \n",
       "1034   22     62     1424  198  510  100  155   72  182  351  115   13  207   \n",
       "1035   23     65     1216  199  483   96  139  133  397   38   48   16  179   \n",
       "\n",
       "      PTS    FG%    FT%   MPG   PPG  RPG  APG  \n",
       "0     720  0.432  0.804  28.0  13.1  4.1  2.1  \n",
       "1     246  0.392  0.707  21.9   7.7  4.6  2.8  \n",
       "2     510  0.440  0.889  19.2   7.7  2.4  1.8  \n",
       "3     161  0.438  0.778  16.5   5.2  3.5  1.1  \n",
       "4     700  0.618  0.759  22.4  12.1  5.9  1.4  \n",
       "...   ...    ...    ...   ...   ...  ...  ...  \n",
       "1031  231  0.488  0.636  11.0   3.6  3.4  0.7  \n",
       "1032  311  0.482  0.707   9.6   5.8  2.7  0.4  \n",
       "1033  611  0.434  0.798  21.9   7.5  3.5  2.2  \n",
       "1034  496  0.388  0.645  23.0   8.0  2.9  5.7  \n",
       "1035  494  0.412  0.691  18.7   7.6  6.1  0.6  \n",
       "\n",
       "[1036 rows x 20 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features_ds_raw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "de8ae377",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>WS_25</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1031</th>\n",
       "      <td>4.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1032</th>\n",
       "      <td>4.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1033</th>\n",
       "      <td>4.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1034</th>\n",
       "      <td>3.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1035</th>\n",
       "      <td>2.4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1036 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      WS_25\n",
       "0       0.0\n",
       "1       2.5\n",
       "2       0.6\n",
       "3       0.8\n",
       "4       6.3\n",
       "...     ...\n",
       "1031    4.1\n",
       "1032    4.3\n",
       "1033    4.5\n",
       "1034    3.3\n",
       "1035    2.4\n",
       "\n",
       "[1036 rows x 1 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels_ds_raw"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb1ae619",
   "metadata": {},
   "source": [
    "## Normalization of Feature Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b318cba2",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "feature_normalization_layer = tf.keras.layers.Normalization(axis=-1)\n",
    "feature_normalization_layer.adapt(features_ds_raw)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "076f665a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "features_ds_normalized = feature_normalization_layer(features_ds_raw)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3a029c43",
   "metadata": {},
   "outputs": [],
   "source": [
    "features_ds = np.array(features_ds_normalized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2b627b48",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.587192  , -1.133756  ,  0.03314409, ...,  0.9669427 ,\n",
       "         0.09333976,  0.11713215],\n",
       "       [ 0.8004314 , -2.9718945 , -1.2081058 , ..., -0.21646269,\n",
       "         0.3200158 ,  0.55341506],\n",
       "       [ 0.8004314 , -0.2546463 , -0.36978245, ..., -0.21646269,\n",
       "        -0.6773586 , -0.06984619],\n",
       "       ...,\n",
       "       [ 0.8004314 ,  0.94413966,  0.37555787, ..., -0.26029247,\n",
       "        -0.17867143,  0.17945836],\n",
       "       [ 0.01367071, -0.5743225 , -0.13953872, ..., -0.1507179 ,\n",
       "        -0.4506826 ,  2.3608725 ],\n",
       "       [ 0.8004314 , -0.33456534, -0.44653037, ..., -0.23837757,\n",
       "         1.0000439 , -0.81775963]], dtype=float32)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features_ds"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e6f8a8c",
   "metadata": {},
   "source": [
    "## Normalization of Label Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4d18b4b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "epsilon = 0.0001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "185f3f03",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "labels_column_means = labels_ds_raw.mean(axis=0)\n",
    "labels_column_std = labels_ds_raw.std(0) + epsilon\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a88b440f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "WS_25    4.16583\n",
       "dtype: float64"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels_column_means"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "38fc9ae6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "WS_25    3.307225\n",
       "dtype: float64"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels_column_std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "5a57b2ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "labels_ds_normalized = (labels_ds_raw - labels_column_means) / labels_column_std\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "5c46c8cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_ds = np.array(labels_ds_normalized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "d30816ce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-1.25961514],\n",
       "       [-0.50369429],\n",
       "       [-1.07819413],\n",
       "       ...,\n",
       "       [ 0.10104239],\n",
       "       [-0.26179962],\n",
       "       [-0.53393112]])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels_ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "0cf68849",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def denormalize(input_label_normalized):\n",
    "    \n",
    "    input_label_raw = (input_label_normalized * labels_column_std[0]) + labels_column_means[0] \n",
    "    \n",
    "    return input_label_raw\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d4e4040",
   "metadata": {},
   "source": [
    "## K Fold Validation with 20Folds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "52473a1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "1d5a36bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "kf = KFold(n_splits=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "18e791b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "mae_list = []\n",
    "r2_list = []\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "3d53b18e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "best_r2 = -np.inf\n",
    "best_weights = None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "24c0e928",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = labels_ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "1b2b0f75",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = features_ds_pca_kmeans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "5e571c07",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "model = Sequential()\n",
    "\n",
    "model.add(Dense(units=1024, activation='relu', kernel_regularizer=regularizers.l2(0.01)))\n",
    "model.add(Dropout(0.25))\n",
    "model.add(Dense(units=512, activation='relu', kernel_regularizer=regularizers.l2(0.01)))\n",
    "model.add(Dropout(0.25))\n",
    "model.add(Dense(units=256, activation='relu', kernel_regularizer=regularizers.l2(0.01)))\n",
    "model.add(Dropout(0.25))\n",
    "model.add(Dense(units=128, activation='relu', kernel_regularizer=regularizers.l2(0.01)))\n",
    "model.add(Dropout(0.25))\n",
    "    \n",
    "model.add(Dense(units=1, activation='linear'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "0ff7bfed",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "callback = tf.keras.callbacks.EarlyStopping (\n",
    "        monitor = 'mean_absolute_error',\n",
    "        patience = 5,\n",
    "        restore_best_weights = True\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "9e087a58",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_weights('Model-0.69.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "a62c7719",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "30/30 [==============================] - 2s 28ms/step - loss: 0.6290 - mean_absolute_error: 0.5633 - val_loss: 0.4247 - val_mean_absolute_error: 0.4432\n",
      "Epoch 2/50\n",
      "30/30 [==============================] - 1s 19ms/step - loss: 0.6193 - mean_absolute_error: 0.5552 - val_loss: 0.4273 - val_mean_absolute_error: 0.4454\n",
      "Epoch 3/50\n",
      "30/30 [==============================] - 1s 22ms/step - loss: 0.6052 - mean_absolute_error: 0.5470 - val_loss: 0.4283 - val_mean_absolute_error: 0.4463\n",
      "Epoch 4/50\n",
      "30/30 [==============================] - 1s 20ms/step - loss: 0.6100 - mean_absolute_error: 0.5515 - val_loss: 0.4329 - val_mean_absolute_error: 0.4525\n",
      "Epoch 5/50\n",
      "30/30 [==============================] - 1s 21ms/step - loss: 0.6182 - mean_absolute_error: 0.5633 - val_loss: 0.4274 - val_mean_absolute_error: 0.4463\n",
      "Epoch 6/50\n",
      "30/30 [==============================] - 1s 21ms/step - loss: 0.5993 - mean_absolute_error: 0.5503 - val_loss: 0.4285 - val_mean_absolute_error: 0.4469\n",
      "Epoch 7/50\n",
      "30/30 [==============================] - 1s 19ms/step - loss: 0.5876 - mean_absolute_error: 0.5379 - val_loss: 0.4380 - val_mean_absolute_error: 0.4558\n",
      "Epoch 8/50\n",
      "30/30 [==============================] - 1s 21ms/step - loss: 0.6071 - mean_absolute_error: 0.5502 - val_loss: 0.4389 - val_mean_absolute_error: 0.4556\n",
      "Epoch 9/50\n",
      "30/30 [==============================] - 1s 21ms/step - loss: 0.5893 - mean_absolute_error: 0.5421 - val_loss: 0.4453 - val_mean_absolute_error: 0.4607\n",
      "Epoch 10/50\n",
      "30/30 [==============================] - 1s 21ms/step - loss: 0.6067 - mean_absolute_error: 0.5525 - val_loss: 0.4277 - val_mean_absolute_error: 0.4451\n",
      "Epoch 11/50\n",
      "30/30 [==============================] - 1s 21ms/step - loss: 0.5959 - mean_absolute_error: 0.5456 - val_loss: 0.4368 - val_mean_absolute_error: 0.4558\n",
      "Epoch 12/50\n",
      "30/30 [==============================] - 1s 21ms/step - loss: 0.6047 - mean_absolute_error: 0.5510 - val_loss: 0.4415 - val_mean_absolute_error: 0.4601\n",
      "4/4 [==============================] - 0s 5ms/step\n",
      "Epoch 1/50\n",
      "30/30 [==============================] - 2s 28ms/step - loss: 0.5871 - mean_absolute_error: 0.5401 - val_loss: 0.6046 - val_mean_absolute_error: 0.5293\n",
      "Epoch 2/50\n",
      "30/30 [==============================] - 1s 18ms/step - loss: 0.5786 - mean_absolute_error: 0.5382 - val_loss: 0.6101 - val_mean_absolute_error: 0.5340\n",
      "Epoch 3/50\n",
      "30/30 [==============================] - 1s 22ms/step - loss: 0.5637 - mean_absolute_error: 0.5295 - val_loss: 0.6145 - val_mean_absolute_error: 0.5384\n",
      "Epoch 4/50\n",
      "30/30 [==============================] - 1s 21ms/step - loss: 0.5764 - mean_absolute_error: 0.5323 - val_loss: 0.6089 - val_mean_absolute_error: 0.5355\n",
      "Epoch 5/50\n",
      "30/30 [==============================] - 1s 19ms/step - loss: 0.6047 - mean_absolute_error: 0.5506 - val_loss: 0.6099 - val_mean_absolute_error: 0.5331\n",
      "Epoch 6/50\n",
      "30/30 [==============================] - 1s 20ms/step - loss: 0.5888 - mean_absolute_error: 0.5477 - val_loss: 0.6146 - val_mean_absolute_error: 0.5353\n",
      "Epoch 7/50\n",
      "30/30 [==============================] - 1s 19ms/step - loss: 0.5650 - mean_absolute_error: 0.5314 - val_loss: 0.6178 - val_mean_absolute_error: 0.5346\n",
      "Epoch 8/50\n",
      "30/30 [==============================] - 1s 19ms/step - loss: 0.5775 - mean_absolute_error: 0.5379 - val_loss: 0.6184 - val_mean_absolute_error: 0.5377\n",
      "4/4 [==============================] - 0s 5ms/step\n",
      "Epoch 1/50\n",
      "30/30 [==============================] - 2s 28ms/step - loss: 0.5997 - mean_absolute_error: 0.5488 - val_loss: 0.5098 - val_mean_absolute_error: 0.5141\n",
      "Epoch 2/50\n",
      "30/30 [==============================] - 1s 19ms/step - loss: 0.5908 - mean_absolute_error: 0.5463 - val_loss: 0.5067 - val_mean_absolute_error: 0.5126\n",
      "Epoch 3/50\n",
      "30/30 [==============================] - 1s 20ms/step - loss: 0.6213 - mean_absolute_error: 0.5587 - val_loss: 0.5190 - val_mean_absolute_error: 0.5192\n",
      "Epoch 4/50\n",
      "30/30 [==============================] - 1s 20ms/step - loss: 0.5995 - mean_absolute_error: 0.5442 - val_loss: 0.5309 - val_mean_absolute_error: 0.5264\n",
      "Epoch 5/50\n",
      "30/30 [==============================] - 1s 20ms/step - loss: 0.5887 - mean_absolute_error: 0.5469 - val_loss: 0.5246 - val_mean_absolute_error: 0.5234\n",
      "Epoch 6/50\n",
      "30/30 [==============================] - 1s 20ms/step - loss: 0.5851 - mean_absolute_error: 0.5378 - val_loss: 0.5264 - val_mean_absolute_error: 0.5238\n",
      "Epoch 7/50\n",
      "30/30 [==============================] - 1s 20ms/step - loss: 0.5822 - mean_absolute_error: 0.5408 - val_loss: 0.5324 - val_mean_absolute_error: 0.5295\n",
      "Epoch 8/50\n",
      "30/30 [==============================] - 1s 20ms/step - loss: 0.5910 - mean_absolute_error: 0.5408 - val_loss: 0.5287 - val_mean_absolute_error: 0.5280\n",
      "Epoch 9/50\n",
      "30/30 [==============================] - 1s 19ms/step - loss: 0.5819 - mean_absolute_error: 0.5395 - val_loss: 0.5276 - val_mean_absolute_error: 0.5266\n",
      "Epoch 10/50\n",
      "30/30 [==============================] - 1s 20ms/step - loss: 0.5885 - mean_absolute_error: 0.5326 - val_loss: 0.5221 - val_mean_absolute_error: 0.5230\n",
      "Epoch 11/50\n",
      "30/30 [==============================] - 1s 21ms/step - loss: 0.5748 - mean_absolute_error: 0.5409 - val_loss: 0.5328 - val_mean_absolute_error: 0.5299\n",
      "Epoch 12/50\n",
      "30/30 [==============================] - 1s 20ms/step - loss: 0.5814 - mean_absolute_error: 0.5383 - val_loss: 0.5359 - val_mean_absolute_error: 0.5326\n",
      "Epoch 13/50\n",
      "30/30 [==============================] - 1s 21ms/step - loss: 0.5849 - mean_absolute_error: 0.5359 - val_loss: 0.5364 - val_mean_absolute_error: 0.5328\n",
      "Epoch 14/50\n",
      "30/30 [==============================] - 1s 18ms/step - loss: 0.5757 - mean_absolute_error: 0.5320 - val_loss: 0.5386 - val_mean_absolute_error: 0.5341\n",
      "Epoch 15/50\n",
      "30/30 [==============================] - 1s 20ms/step - loss: 0.5716 - mean_absolute_error: 0.5339 - val_loss: 0.5375 - val_mean_absolute_error: 0.5344\n",
      "Epoch 16/50\n",
      "30/30 [==============================] - 1s 19ms/step - loss: 0.5857 - mean_absolute_error: 0.5413 - val_loss: 0.5471 - val_mean_absolute_error: 0.5401\n",
      "Epoch 17/50\n",
      "30/30 [==============================] - 1s 22ms/step - loss: 0.5701 - mean_absolute_error: 0.5260 - val_loss: 0.5433 - val_mean_absolute_error: 0.5358\n",
      "Epoch 18/50\n",
      "30/30 [==============================] - 1s 21ms/step - loss: 0.5646 - mean_absolute_error: 0.5333 - val_loss: 0.5440 - val_mean_absolute_error: 0.5352\n",
      "Epoch 19/50\n",
      "30/30 [==============================] - 1s 22ms/step - loss: 0.5571 - mean_absolute_error: 0.5180 - val_loss: 0.5545 - val_mean_absolute_error: 0.5413\n",
      "Epoch 20/50\n",
      "30/30 [==============================] - 1s 20ms/step - loss: 0.5647 - mean_absolute_error: 0.5298 - val_loss: 0.5418 - val_mean_absolute_error: 0.5326\n",
      "Epoch 21/50\n",
      "30/30 [==============================] - 1s 20ms/step - loss: 0.5666 - mean_absolute_error: 0.5279 - val_loss: 0.5429 - val_mean_absolute_error: 0.5318\n",
      "Epoch 22/50\n",
      "30/30 [==============================] - 1s 22ms/step - loss: 0.5857 - mean_absolute_error: 0.5370 - val_loss: 0.5478 - val_mean_absolute_error: 0.5366\n",
      "Epoch 23/50\n",
      "30/30 [==============================] - 1s 21ms/step - loss: 0.5525 - mean_absolute_error: 0.5231 - val_loss: 0.5528 - val_mean_absolute_error: 0.5365\n",
      "Epoch 24/50\n",
      "30/30 [==============================] - 1s 21ms/step - loss: 0.5795 - mean_absolute_error: 0.5345 - val_loss: 0.5521 - val_mean_absolute_error: 0.5381\n",
      "4/4 [==============================] - 0s 5ms/step\n",
      "Epoch 1/50\n",
      "30/30 [==============================] - 2s 30ms/step - loss: 0.5712 - mean_absolute_error: 0.5393 - val_loss: 0.4918 - val_mean_absolute_error: 0.4978\n",
      "Epoch 2/50\n",
      "30/30 [==============================] - 1s 22ms/step - loss: 0.5722 - mean_absolute_error: 0.5378 - val_loss: 0.4877 - val_mean_absolute_error: 0.4932\n",
      "Epoch 3/50\n",
      "30/30 [==============================] - 1s 18ms/step - loss: 0.5650 - mean_absolute_error: 0.5244 - val_loss: 0.4983 - val_mean_absolute_error: 0.4992\n",
      "Epoch 4/50\n",
      "30/30 [==============================] - 1s 23ms/step - loss: 0.5627 - mean_absolute_error: 0.5272 - val_loss: 0.4865 - val_mean_absolute_error: 0.4900\n",
      "Epoch 5/50\n",
      "30/30 [==============================] - 1s 20ms/step - loss: 0.5563 - mean_absolute_error: 0.5249 - val_loss: 0.4944 - val_mean_absolute_error: 0.4954\n",
      "Epoch 6/50\n",
      "30/30 [==============================] - 1s 22ms/step - loss: 0.5630 - mean_absolute_error: 0.5263 - val_loss: 0.5002 - val_mean_absolute_error: 0.4978\n",
      "Epoch 7/50\n",
      "30/30 [==============================] - 1s 21ms/step - loss: 0.5759 - mean_absolute_error: 0.5359 - val_loss: 0.5037 - val_mean_absolute_error: 0.4967\n",
      "Epoch 8/50\n",
      "30/30 [==============================] - 1s 20ms/step - loss: 0.5546 - mean_absolute_error: 0.5286 - val_loss: 0.5152 - val_mean_absolute_error: 0.5031\n",
      "4/4 [==============================] - 0s 4ms/step\n",
      "Epoch 1/50\n",
      "30/30 [==============================] - 2s 29ms/step - loss: 0.5756 - mean_absolute_error: 0.5394 - val_loss: 0.5787 - val_mean_absolute_error: 0.5006\n",
      "Epoch 2/50\n",
      "30/30 [==============================] - 1s 20ms/step - loss: 0.5504 - mean_absolute_error: 0.5296 - val_loss: 0.5803 - val_mean_absolute_error: 0.5008\n",
      "Epoch 3/50\n",
      "30/30 [==============================] - 1s 18ms/step - loss: 0.5588 - mean_absolute_error: 0.5316 - val_loss: 0.5934 - val_mean_absolute_error: 0.5067\n",
      "Epoch 4/50\n",
      "30/30 [==============================] - 1s 21ms/step - loss: 0.5560 - mean_absolute_error: 0.5244 - val_loss: 0.5938 - val_mean_absolute_error: 0.5083\n",
      "Epoch 5/50\n",
      "30/30 [==============================] - 1s 20ms/step - loss: 0.5309 - mean_absolute_error: 0.5131 - val_loss: 0.6004 - val_mean_absolute_error: 0.5112\n",
      "Epoch 6/50\n",
      "30/30 [==============================] - 1s 20ms/step - loss: 0.5528 - mean_absolute_error: 0.5290 - val_loss: 0.6055 - val_mean_absolute_error: 0.5141\n",
      "Epoch 7/50\n",
      "30/30 [==============================] - 1s 20ms/step - loss: 0.5433 - mean_absolute_error: 0.5171 - val_loss: 0.6096 - val_mean_absolute_error: 0.5148\n",
      "Epoch 8/50\n",
      "30/30 [==============================] - 1s 20ms/step - loss: 0.5730 - mean_absolute_error: 0.5328 - val_loss: 0.6151 - val_mean_absolute_error: 0.5188\n",
      "Epoch 9/50\n",
      "30/30 [==============================] - 1s 21ms/step - loss: 0.5566 - mean_absolute_error: 0.5311 - val_loss: 0.6134 - val_mean_absolute_error: 0.5161\n",
      "Epoch 10/50\n",
      "30/30 [==============================] - 1s 22ms/step - loss: 0.5473 - mean_absolute_error: 0.5228 - val_loss: 0.6215 - val_mean_absolute_error: 0.5194\n",
      "4/4 [==============================] - 0s 3ms/step\n",
      "Epoch 1/50\n",
      "30/30 [==============================] - 2s 29ms/step - loss: 0.5545 - mean_absolute_error: 0.5233 - val_loss: 0.4254 - val_mean_absolute_error: 0.4675\n",
      "Epoch 2/50\n",
      "30/30 [==============================] - 1s 20ms/step - loss: 0.5747 - mean_absolute_error: 0.5353 - val_loss: 0.4232 - val_mean_absolute_error: 0.4655\n",
      "Epoch 3/50\n",
      "30/30 [==============================] - 1s 21ms/step - loss: 0.5915 - mean_absolute_error: 0.5425 - val_loss: 0.4449 - val_mean_absolute_error: 0.4816\n",
      "Epoch 4/50\n",
      "30/30 [==============================] - 1s 21ms/step - loss: 0.5808 - mean_absolute_error: 0.5383 - val_loss: 0.4378 - val_mean_absolute_error: 0.4765\n",
      "Epoch 5/50\n",
      "30/30 [==============================] - 1s 20ms/step - loss: 0.5711 - mean_absolute_error: 0.5320 - val_loss: 0.4493 - val_mean_absolute_error: 0.4854\n",
      "Epoch 6/50\n",
      "30/30 [==============================] - 1s 20ms/step - loss: 0.5818 - mean_absolute_error: 0.5358 - val_loss: 0.4500 - val_mean_absolute_error: 0.4846\n",
      "4/4 [==============================] - 0s 5ms/step\n",
      "Epoch 1/50\n",
      "30/30 [==============================] - 2s 30ms/step - loss: 0.5673 - mean_absolute_error: 0.5292 - val_loss: 0.5823 - val_mean_absolute_error: 0.5429\n",
      "Epoch 2/50\n",
      "30/30 [==============================] - 1s 20ms/step - loss: 0.5519 - mean_absolute_error: 0.5184 - val_loss: 0.5855 - val_mean_absolute_error: 0.5448\n",
      "Epoch 3/50\n",
      "30/30 [==============================] - 1s 21ms/step - loss: 0.5490 - mean_absolute_error: 0.5184 - val_loss: 0.5833 - val_mean_absolute_error: 0.5434\n",
      "Epoch 4/50\n",
      "30/30 [==============================] - 1s 19ms/step - loss: 0.5238 - mean_absolute_error: 0.4989 - val_loss: 0.5840 - val_mean_absolute_error: 0.5392\n",
      "Epoch 5/50\n",
      "30/30 [==============================] - 1s 20ms/step - loss: 0.5507 - mean_absolute_error: 0.5233 - val_loss: 0.5942 - val_mean_absolute_error: 0.5467\n",
      "Epoch 6/50\n",
      "30/30 [==============================] - 1s 19ms/step - loss: 0.5371 - mean_absolute_error: 0.5120 - val_loss: 0.5976 - val_mean_absolute_error: 0.5498\n",
      "Epoch 7/50\n",
      "30/30 [==============================] - 1s 20ms/step - loss: 0.5510 - mean_absolute_error: 0.5244 - val_loss: 0.6000 - val_mean_absolute_error: 0.5545\n",
      "Epoch 8/50\n",
      "30/30 [==============================] - 1s 20ms/step - loss: 0.5635 - mean_absolute_error: 0.5256 - val_loss: 0.6002 - val_mean_absolute_error: 0.5560\n",
      "Epoch 9/50\n",
      "30/30 [==============================] - 1s 20ms/step - loss: 0.5429 - mean_absolute_error: 0.5204 - val_loss: 0.6053 - val_mean_absolute_error: 0.5545\n",
      "4/4 [==============================] - 0s 3ms/step\n",
      "Epoch 1/50\n",
      "30/30 [==============================] - 2s 29ms/step - loss: 0.5604 - mean_absolute_error: 0.5240 - val_loss: 0.5532 - val_mean_absolute_error: 0.5088\n",
      "Epoch 2/50\n",
      "30/30 [==============================] - 1s 18ms/step - loss: 0.5557 - mean_absolute_error: 0.5204 - val_loss: 0.5503 - val_mean_absolute_error: 0.5108\n",
      "Epoch 3/50\n",
      "30/30 [==============================] - 1s 21ms/step - loss: 0.5768 - mean_absolute_error: 0.5427 - val_loss: 0.5766 - val_mean_absolute_error: 0.5262\n",
      "Epoch 4/50\n",
      "30/30 [==============================] - 1s 19ms/step - loss: 0.5608 - mean_absolute_error: 0.5301 - val_loss: 0.5679 - val_mean_absolute_error: 0.5213\n",
      "Epoch 5/50\n",
      "30/30 [==============================] - 1s 21ms/step - loss: 0.5439 - mean_absolute_error: 0.5214 - val_loss: 0.5790 - val_mean_absolute_error: 0.5269\n",
      "Epoch 6/50\n",
      "30/30 [==============================] - 1s 21ms/step - loss: 0.5478 - mean_absolute_error: 0.5165 - val_loss: 0.5897 - val_mean_absolute_error: 0.5322\n",
      "Epoch 7/50\n",
      "30/30 [==============================] - 1s 20ms/step - loss: 0.5324 - mean_absolute_error: 0.5170 - val_loss: 0.5738 - val_mean_absolute_error: 0.5239\n",
      "Epoch 8/50\n",
      "30/30 [==============================] - 1s 21ms/step - loss: 0.5755 - mean_absolute_error: 0.5344 - val_loss: 0.6001 - val_mean_absolute_error: 0.5382\n",
      "Epoch 9/50\n",
      "30/30 [==============================] - 1s 19ms/step - loss: 0.5483 - mean_absolute_error: 0.5243 - val_loss: 0.5982 - val_mean_absolute_error: 0.5376\n",
      "Epoch 10/50\n",
      "30/30 [==============================] - 1s 20ms/step - loss: 0.5448 - mean_absolute_error: 0.5262 - val_loss: 0.5905 - val_mean_absolute_error: 0.5359\n",
      "Epoch 11/50\n",
      "30/30 [==============================] - 1s 21ms/step - loss: 0.5436 - mean_absolute_error: 0.5258 - val_loss: 0.5873 - val_mean_absolute_error: 0.5322\n",
      "4/4 [==============================] - 0s 6ms/step\n",
      "Epoch 1/50\n",
      "30/30 [==============================] - 2s 30ms/step - loss: 0.5636 - mean_absolute_error: 0.5349 - val_loss: 0.5021 - val_mean_absolute_error: 0.5070\n",
      "Epoch 2/50\n",
      "30/30 [==============================] - 1s 17ms/step - loss: 0.5578 - mean_absolute_error: 0.5259 - val_loss: 0.5106 - val_mean_absolute_error: 0.5107\n",
      "Epoch 3/50\n",
      "30/30 [==============================] - 1s 19ms/step - loss: 0.5446 - mean_absolute_error: 0.5166 - val_loss: 0.5173 - val_mean_absolute_error: 0.5136\n",
      "Epoch 4/50\n",
      "30/30 [==============================] - 1s 21ms/step - loss: 0.5740 - mean_absolute_error: 0.5293 - val_loss: 0.5198 - val_mean_absolute_error: 0.5164\n",
      "Epoch 5/50\n",
      "30/30 [==============================] - 1s 20ms/step - loss: 0.5458 - mean_absolute_error: 0.5202 - val_loss: 0.5290 - val_mean_absolute_error: 0.5214\n",
      "Epoch 6/50\n",
      "30/30 [==============================] - 1s 20ms/step - loss: 0.5511 - mean_absolute_error: 0.5283 - val_loss: 0.5269 - val_mean_absolute_error: 0.5205\n",
      "Epoch 7/50\n",
      "30/30 [==============================] - 1s 20ms/step - loss: 0.5200 - mean_absolute_error: 0.5057 - val_loss: 0.5351 - val_mean_absolute_error: 0.5236\n",
      "Epoch 8/50\n",
      "30/30 [==============================] - 1s 19ms/step - loss: 0.5457 - mean_absolute_error: 0.5160 - val_loss: 0.5406 - val_mean_absolute_error: 0.5270\n",
      "Epoch 9/50\n",
      "30/30 [==============================] - 1s 20ms/step - loss: 0.5402 - mean_absolute_error: 0.5108 - val_loss: 0.5466 - val_mean_absolute_error: 0.5310\n",
      "Epoch 10/50\n",
      "30/30 [==============================] - 1s 20ms/step - loss: 0.5520 - mean_absolute_error: 0.5219 - val_loss: 0.5446 - val_mean_absolute_error: 0.5302\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11/50\n",
      "30/30 [==============================] - 1s 21ms/step - loss: 0.5558 - mean_absolute_error: 0.5264 - val_loss: 0.5453 - val_mean_absolute_error: 0.5293\n",
      "Epoch 12/50\n",
      "30/30 [==============================] - 1s 21ms/step - loss: 0.5651 - mean_absolute_error: 0.5284 - val_loss: 0.5535 - val_mean_absolute_error: 0.5319\n",
      "4/4 [==============================] - 0s 5ms/step\n",
      "Epoch 1/50\n",
      "30/30 [==============================] - 2s 29ms/step - loss: 0.5676 - mean_absolute_error: 0.5228 - val_loss: 0.5062 - val_mean_absolute_error: 0.4986\n",
      "Epoch 2/50\n",
      "30/30 [==============================] - 1s 19ms/step - loss: 0.5408 - mean_absolute_error: 0.5154 - val_loss: 0.5157 - val_mean_absolute_error: 0.5035\n",
      "Epoch 3/50\n",
      "30/30 [==============================] - 1s 18ms/step - loss: 0.5450 - mean_absolute_error: 0.5188 - val_loss: 0.5206 - val_mean_absolute_error: 0.5049\n",
      "Epoch 4/50\n",
      "30/30 [==============================] - 1s 19ms/step - loss: 0.5505 - mean_absolute_error: 0.5188 - val_loss: 0.5227 - val_mean_absolute_error: 0.5086\n",
      "Epoch 5/50\n",
      "30/30 [==============================] - 1s 21ms/step - loss: 0.5474 - mean_absolute_error: 0.5176 - val_loss: 0.5278 - val_mean_absolute_error: 0.5106\n",
      "Epoch 6/50\n",
      "30/30 [==============================] - 1s 21ms/step - loss: 0.5539 - mean_absolute_error: 0.5234 - val_loss: 0.5338 - val_mean_absolute_error: 0.5122\n",
      "Epoch 7/50\n",
      "30/30 [==============================] - 1s 20ms/step - loss: 0.5451 - mean_absolute_error: 0.5179 - val_loss: 0.5314 - val_mean_absolute_error: 0.5146\n",
      "4/4 [==============================] - 0s 5ms/step\n"
     ]
    }
   ],
   "source": [
    "\n",
    "for train_index, test_index in kf.split(X):\n",
    "    \n",
    "    x_train, x_test = X[train_index], X[test_index]\n",
    "    y_train, y_test = y[train_index], y[test_index]\n",
    "    \n",
    "    model.compile(loss='mse', optimizer=Adam(learning_rate=0.0001), metrics=['mean_absolute_error'])\n",
    "    \n",
    "    model.fit(\n",
    "        x_train, \n",
    "        y_train, \n",
    "        epochs=50, \n",
    "        callbacks = [callback], \n",
    "        validation_data=(x_test, y_test)\n",
    "    )\n",
    "    \n",
    "    y_pred_normalized = model.predict(x_test)\n",
    "    \n",
    "    mae = mean_absolute_error(y_test, y_pred_normalized)\n",
    "    r2 = r2_score(y_test, y_pred_normalized)\n",
    "    \n",
    "    if r2 > best_r2:\n",
    "        best_r2 = r2\n",
    "        best_model = model\n",
    "    \n",
    "    mae_list.append(mae)\n",
    "    r2_list.append(r2)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "2c0e513b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_10 (Dense)            (None, 1024)              22528     \n",
      "                                                                 \n",
      " dropout_8 (Dropout)         (None, 1024)              0         \n",
      "                                                                 \n",
      " dense_11 (Dense)            (None, 512)               524800    \n",
      "                                                                 \n",
      " dropout_9 (Dropout)         (None, 512)               0         \n",
      "                                                                 \n",
      " dense_12 (Dense)            (None, 256)               131328    \n",
      "                                                                 \n",
      " dropout_10 (Dropout)        (None, 256)               0         \n",
      "                                                                 \n",
      " dense_13 (Dense)            (None, 128)               32896     \n",
      "                                                                 \n",
      " dropout_11 (Dropout)        (None, 128)               0         \n",
      "                                                                 \n",
      " dense_14 (Dense)            (None, 1)                 129       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 711,681\n",
      "Trainable params: 711,681\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "40ebdc60",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean MAE: 0.511195436026916\n",
      "Mean R2: 0.5605325438453214\n"
     ]
    }
   ],
   "source": [
    "\n",
    "mean_mae = np.mean(mae_list)\n",
    "print(\"Mean MAE:\", mean_mae)\n",
    "\n",
    "mean_r2 = np.mean(r2_list)\n",
    "print(\"Mean R2:\", mean_r2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "d13f984d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best MAE: 0.4558139085953271\n",
      "Best R2: 0.6722055934478701\n"
     ]
    }
   ],
   "source": [
    "\n",
    "best_mae = np.min(mae_list)\n",
    "print(\"Best MAE:\", best_mae)\n",
    "\n",
    "best_r2 = np.max(r2_list)\n",
    "print(\"Best R2:\", best_r2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9677ecc",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model.save_weights('Model-0.69.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1052f6dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "n_train1, n_test1, x_train1, x_test1, y_train1, y_test1 = train_test_split(names_ds, X, y, test_size=0.3)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ed3b46c",
   "metadata": {},
   "source": [
    "### R2 on Entire Dataset (Normalized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "b6a9a01f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "33/33 [==============================] - 0s 5ms/step - loss: 0.4850 - mean_absolute_error: 0.4800\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.4850108325481415, 0.4800297021865845]"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "46013c46",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "33/33 [==============================] - 0s 4ms/step\n"
     ]
    }
   ],
   "source": [
    "y_pred_normalized = model.predict(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "1d7cb66d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.4800297125707189\n",
      "0.6326198439323807\n"
     ]
    }
   ],
   "source": [
    "\n",
    "mae_normalized = mean_absolute_error(labels_ds, y_pred_normalized)\n",
    "print(mae_normalized)\n",
    "\n",
    "r2_score_normalized = r2_score(labels_ds, y_pred_normalized)\n",
    "print(r2_score_normalized)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46e75fe6",
   "metadata": {},
   "source": [
    "### R2 on Entire Dataset (Raw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "79e61601",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "33/33 [==============================] - 0s 3ms/step\n"
     ]
    }
   ],
   "source": [
    "y_pred_raw = denormalize(model.predict(X))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "9db75209",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.5875660567209986\n",
      "0.6326198419200653\n"
     ]
    }
   ],
   "source": [
    "\n",
    "mae_raw = mean_absolute_error(labels_ds_raw, y_pred_raw)\n",
    "print(mae_raw)\n",
    "\n",
    "r2_score_raw = r2_score(labels_ds_raw, y_pred_raw)\n",
    "print(r2_score_raw)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24f4150e",
   "metadata": {},
   "source": [
    "# Data Visualization "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a30e98b",
   "metadata": {},
   "source": [
    "## Histogram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4200ccb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "sb.histplot(data=features_ds_raw)\n",
    "plt.legend(features_ds_raw.head(), bbox_to_anchor=(1.02, 1), loc='upper left', borderaxespad=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "243b0515",
   "metadata": {},
   "outputs": [],
   "source": [
    "sb.histplot(data=features_ds)\n",
    "plt.legend(features_ds_raw.head(), bbox_to_anchor=(1.02, 1), loc='upper left', borderaxespad=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d95fe47",
   "metadata": {},
   "outputs": [],
   "source": [
    "sb.histplot(data=features_ds_K_Means)\n",
    "plt.legend(np.arange(features_ds_K_Means.shape[1]), bbox_to_anchor=(1.02, 1), loc='upper left', borderaxespad=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bec69097",
   "metadata": {},
   "outputs": [],
   "source": [
    "sb.histplot(data=features_ds_pca)\n",
    "plt.legend(np.arange(features_ds_pca.shape[1]), bbox_to_anchor=(1.02, 1), loc='upper left', borderaxespad=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e988bfb4",
   "metadata": {},
   "source": [
    "# Boxplot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41876f19",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams.update({'font.size': 15})\n",
    "fig, ax = plt.subplots(figsize=(30, 20))\n",
    "sb.boxplot(data=features_ds_raw, ax=ax)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b88d421",
   "metadata": {},
   "source": [
    "## Correlation Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0808793",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "C_mat = features_ds_raw.corr()\n",
    "C_mat\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45d75b20",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "plt.rcParams.update({'font.size': 8})\n",
    "fig = plt.figure(figsize = (8,8))\n",
    "sb.heatmap(C_mat, vmax=.8, square=True)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f461c36",
   "metadata": {},
   "source": [
    "## Filter Feature Selection Techniques"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2aad41a",
   "metadata": {},
   "source": [
    "### Univariate Feature Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "630a38d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "f_val, p_val = f_regression(features_ds, np.array(labels_ds).ravel())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69a3f070",
   "metadata": {},
   "outputs": [],
   "source": [
    "f_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32afc960",
   "metadata": {},
   "outputs": [],
   "source": [
    "p_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7107777a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "feature_dictonary={'features':features_ds_raw.columns.tolist(), 'f_scores':f_val.tolist()}\n",
    "features_f_score= pd.DataFrame(feature_dictonary).sort_values(by='f_scores', ascending=False).reset_index(drop=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ac73b1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "features_f_score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6dc7ec94",
   "metadata": {},
   "source": [
    "### Variance Threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96c3da43",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "variance_filter = VarianceThreshold(threshold=0.25)\n",
    "features_variance_selected = variance_filter.fit_transform(features_ds_raw)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82e74ed1",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(features_variance_selected)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b3546ac",
   "metadata": {},
   "source": [
    "## Principal Component Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "6115730f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "6be42e14",
   "metadata": {},
   "outputs": [],
   "source": [
    "pca_model = PCA()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "f29f9f16",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>PCA()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">PCA</label><div class=\"sk-toggleable__content\"><pre>PCA()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "PCA()"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pca_model.fit(features_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "b3a21be5",
   "metadata": {},
   "outputs": [],
   "source": [
    "features_ds_pca = pca_model.transform(features_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "8918fe10",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "      <th>14</th>\n",
       "      <th>15</th>\n",
       "      <th>16</th>\n",
       "      <th>17</th>\n",
       "      <th>18</th>\n",
       "      <th>19</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.292134</td>\n",
       "      <td>-1.257798</td>\n",
       "      <td>-0.707501</td>\n",
       "      <td>-1.869496</td>\n",
       "      <td>1.177831</td>\n",
       "      <td>0.822886</td>\n",
       "      <td>0.089581</td>\n",
       "      <td>-0.574167</td>\n",
       "      <td>0.762674</td>\n",
       "      <td>0.344767</td>\n",
       "      <td>-0.210416</td>\n",
       "      <td>-0.312725</td>\n",
       "      <td>0.262175</td>\n",
       "      <td>0.281941</td>\n",
       "      <td>0.023277</td>\n",
       "      <td>-0.140330</td>\n",
       "      <td>0.026398</td>\n",
       "      <td>-0.086339</td>\n",
       "      <td>-0.027676</td>\n",
       "      <td>-0.024713</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-3.327180</td>\n",
       "      <td>-0.757063</td>\n",
       "      <td>-1.204306</td>\n",
       "      <td>-0.415835</td>\n",
       "      <td>2.399911</td>\n",
       "      <td>1.717979</td>\n",
       "      <td>-0.156369</td>\n",
       "      <td>-0.177034</td>\n",
       "      <td>-0.333082</td>\n",
       "      <td>-0.166262</td>\n",
       "      <td>0.257170</td>\n",
       "      <td>-0.175745</td>\n",
       "      <td>0.384300</td>\n",
       "      <td>0.161141</td>\n",
       "      <td>0.093361</td>\n",
       "      <td>0.114670</td>\n",
       "      <td>-0.033822</td>\n",
       "      <td>0.139177</td>\n",
       "      <td>0.097603</td>\n",
       "      <td>0.020054</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-2.015606</td>\n",
       "      <td>-1.362153</td>\n",
       "      <td>-0.405446</td>\n",
       "      <td>-1.433654</td>\n",
       "      <td>-0.467715</td>\n",
       "      <td>0.061849</td>\n",
       "      <td>-0.941400</td>\n",
       "      <td>-0.417769</td>\n",
       "      <td>0.592103</td>\n",
       "      <td>-0.012417</td>\n",
       "      <td>-0.298907</td>\n",
       "      <td>0.058895</td>\n",
       "      <td>0.036770</td>\n",
       "      <td>0.066277</td>\n",
       "      <td>0.038942</td>\n",
       "      <td>-0.115642</td>\n",
       "      <td>0.097798</td>\n",
       "      <td>-0.025997</td>\n",
       "      <td>0.074460</td>\n",
       "      <td>-0.040713</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-4.596894</td>\n",
       "      <td>-0.145407</td>\n",
       "      <td>-0.969570</td>\n",
       "      <td>-1.644120</td>\n",
       "      <td>1.998151</td>\n",
       "      <td>1.010000</td>\n",
       "      <td>-0.636268</td>\n",
       "      <td>-0.196166</td>\n",
       "      <td>-0.066107</td>\n",
       "      <td>0.347687</td>\n",
       "      <td>0.055709</td>\n",
       "      <td>-0.046553</td>\n",
       "      <td>0.124933</td>\n",
       "      <td>-0.300156</td>\n",
       "      <td>-0.063901</td>\n",
       "      <td>0.008944</td>\n",
       "      <td>0.077846</td>\n",
       "      <td>0.047546</td>\n",
       "      <td>0.057027</td>\n",
       "      <td>-0.015374</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.049892</td>\n",
       "      <td>1.643681</td>\n",
       "      <td>-0.343754</td>\n",
       "      <td>-1.483563</td>\n",
       "      <td>1.923791</td>\n",
       "      <td>-1.813028</td>\n",
       "      <td>-1.181992</td>\n",
       "      <td>-0.583150</td>\n",
       "      <td>1.041105</td>\n",
       "      <td>0.060921</td>\n",
       "      <td>-0.775561</td>\n",
       "      <td>0.043405</td>\n",
       "      <td>0.367791</td>\n",
       "      <td>0.211550</td>\n",
       "      <td>-0.012893</td>\n",
       "      <td>-0.105319</td>\n",
       "      <td>0.023094</td>\n",
       "      <td>0.008346</td>\n",
       "      <td>-0.004242</td>\n",
       "      <td>0.040277</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1031</th>\n",
       "      <td>-3.179523</td>\n",
       "      <td>1.807039</td>\n",
       "      <td>0.546411</td>\n",
       "      <td>0.404087</td>\n",
       "      <td>0.054136</td>\n",
       "      <td>-0.250871</td>\n",
       "      <td>-0.225722</td>\n",
       "      <td>0.239025</td>\n",
       "      <td>0.294486</td>\n",
       "      <td>-0.461221</td>\n",
       "      <td>0.055090</td>\n",
       "      <td>0.583488</td>\n",
       "      <td>-0.024619</td>\n",
       "      <td>-0.018336</td>\n",
       "      <td>-0.049239</td>\n",
       "      <td>0.009372</td>\n",
       "      <td>-0.107070</td>\n",
       "      <td>-0.003852</td>\n",
       "      <td>0.028336</td>\n",
       "      <td>0.000166</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1032</th>\n",
       "      <td>-3.357408</td>\n",
       "      <td>0.636947</td>\n",
       "      <td>-0.259547</td>\n",
       "      <td>-1.023044</td>\n",
       "      <td>0.701822</td>\n",
       "      <td>-0.669717</td>\n",
       "      <td>0.327507</td>\n",
       "      <td>0.246211</td>\n",
       "      <td>-0.920763</td>\n",
       "      <td>0.521672</td>\n",
       "      <td>-0.149619</td>\n",
       "      <td>0.217559</td>\n",
       "      <td>0.125018</td>\n",
       "      <td>-0.079194</td>\n",
       "      <td>-0.044589</td>\n",
       "      <td>-0.069223</td>\n",
       "      <td>0.037971</td>\n",
       "      <td>-0.083109</td>\n",
       "      <td>0.034924</td>\n",
       "      <td>0.066822</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1033</th>\n",
       "      <td>0.475405</td>\n",
       "      <td>-0.951874</td>\n",
       "      <td>1.057638</td>\n",
       "      <td>-0.566269</td>\n",
       "      <td>-0.912363</td>\n",
       "      <td>0.382992</td>\n",
       "      <td>-0.458896</td>\n",
       "      <td>-0.299393</td>\n",
       "      <td>0.093178</td>\n",
       "      <td>0.560132</td>\n",
       "      <td>-0.148677</td>\n",
       "      <td>0.032868</td>\n",
       "      <td>0.021519</td>\n",
       "      <td>-0.021933</td>\n",
       "      <td>-0.029983</td>\n",
       "      <td>0.072934</td>\n",
       "      <td>0.009080</td>\n",
       "      <td>-0.007498</td>\n",
       "      <td>-0.040534</td>\n",
       "      <td>0.011361</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1034</th>\n",
       "      <td>0.281951</td>\n",
       "      <td>-2.579041</td>\n",
       "      <td>1.511082</td>\n",
       "      <td>1.600706</td>\n",
       "      <td>1.212078</td>\n",
       "      <td>1.070659</td>\n",
       "      <td>-0.014405</td>\n",
       "      <td>0.085989</td>\n",
       "      <td>-0.765637</td>\n",
       "      <td>0.081333</td>\n",
       "      <td>0.780976</td>\n",
       "      <td>0.645499</td>\n",
       "      <td>-0.155930</td>\n",
       "      <td>0.169430</td>\n",
       "      <td>0.200307</td>\n",
       "      <td>0.137249</td>\n",
       "      <td>-0.056131</td>\n",
       "      <td>-0.002074</td>\n",
       "      <td>0.065931</td>\n",
       "      <td>0.025794</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1035</th>\n",
       "      <td>-0.588314</td>\n",
       "      <td>1.231915</td>\n",
       "      <td>0.114124</td>\n",
       "      <td>-0.614644</td>\n",
       "      <td>-0.172459</td>\n",
       "      <td>1.319147</td>\n",
       "      <td>0.441039</td>\n",
       "      <td>-0.920927</td>\n",
       "      <td>-0.673559</td>\n",
       "      <td>0.156526</td>\n",
       "      <td>0.139444</td>\n",
       "      <td>0.288086</td>\n",
       "      <td>0.337843</td>\n",
       "      <td>0.051911</td>\n",
       "      <td>-0.109301</td>\n",
       "      <td>0.051556</td>\n",
       "      <td>-0.002628</td>\n",
       "      <td>-0.001309</td>\n",
       "      <td>0.003644</td>\n",
       "      <td>0.009283</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1036 rows × 20 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            0         1         2         3         4         5         6   \\\n",
       "0    -0.292134 -1.257798 -0.707501 -1.869496  1.177831  0.822886  0.089581   \n",
       "1    -3.327180 -0.757063 -1.204306 -0.415835  2.399911  1.717979 -0.156369   \n",
       "2    -2.015606 -1.362153 -0.405446 -1.433654 -0.467715  0.061849 -0.941400   \n",
       "3    -4.596894 -0.145407 -0.969570 -1.644120  1.998151  1.010000 -0.636268   \n",
       "4    -0.049892  1.643681 -0.343754 -1.483563  1.923791 -1.813028 -1.181992   \n",
       "...        ...       ...       ...       ...       ...       ...       ...   \n",
       "1031 -3.179523  1.807039  0.546411  0.404087  0.054136 -0.250871 -0.225722   \n",
       "1032 -3.357408  0.636947 -0.259547 -1.023044  0.701822 -0.669717  0.327507   \n",
       "1033  0.475405 -0.951874  1.057638 -0.566269 -0.912363  0.382992 -0.458896   \n",
       "1034  0.281951 -2.579041  1.511082  1.600706  1.212078  1.070659 -0.014405   \n",
       "1035 -0.588314  1.231915  0.114124 -0.614644 -0.172459  1.319147  0.441039   \n",
       "\n",
       "            7         8         9         10        11        12        13  \\\n",
       "0    -0.574167  0.762674  0.344767 -0.210416 -0.312725  0.262175  0.281941   \n",
       "1    -0.177034 -0.333082 -0.166262  0.257170 -0.175745  0.384300  0.161141   \n",
       "2    -0.417769  0.592103 -0.012417 -0.298907  0.058895  0.036770  0.066277   \n",
       "3    -0.196166 -0.066107  0.347687  0.055709 -0.046553  0.124933 -0.300156   \n",
       "4    -0.583150  1.041105  0.060921 -0.775561  0.043405  0.367791  0.211550   \n",
       "...        ...       ...       ...       ...       ...       ...       ...   \n",
       "1031  0.239025  0.294486 -0.461221  0.055090  0.583488 -0.024619 -0.018336   \n",
       "1032  0.246211 -0.920763  0.521672 -0.149619  0.217559  0.125018 -0.079194   \n",
       "1033 -0.299393  0.093178  0.560132 -0.148677  0.032868  0.021519 -0.021933   \n",
       "1034  0.085989 -0.765637  0.081333  0.780976  0.645499 -0.155930  0.169430   \n",
       "1035 -0.920927 -0.673559  0.156526  0.139444  0.288086  0.337843  0.051911   \n",
       "\n",
       "            14        15        16        17        18        19  \n",
       "0     0.023277 -0.140330  0.026398 -0.086339 -0.027676 -0.024713  \n",
       "1     0.093361  0.114670 -0.033822  0.139177  0.097603  0.020054  \n",
       "2     0.038942 -0.115642  0.097798 -0.025997  0.074460 -0.040713  \n",
       "3    -0.063901  0.008944  0.077846  0.047546  0.057027 -0.015374  \n",
       "4    -0.012893 -0.105319  0.023094  0.008346 -0.004242  0.040277  \n",
       "...        ...       ...       ...       ...       ...       ...  \n",
       "1031 -0.049239  0.009372 -0.107070 -0.003852  0.028336  0.000166  \n",
       "1032 -0.044589 -0.069223  0.037971 -0.083109  0.034924  0.066822  \n",
       "1033 -0.029983  0.072934  0.009080 -0.007498 -0.040534  0.011361  \n",
       "1034  0.200307  0.137249 -0.056131 -0.002074  0.065931  0.025794  \n",
       "1035 -0.109301  0.051556 -0.002628 -0.001309  0.003644  0.009283  \n",
       "\n",
       "[1036 rows x 20 columns]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(features_ds_pca)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70a44d80",
   "metadata": {},
   "source": [
    "## K-Means Clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "5ee63820",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "f08cc9e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "k_means_model = KMeans(n_init='auto')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "a437ad5b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\oonak\\Anaconda3\\envs\\ITS365\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1382: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=5.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {color: black;background-color: white;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>KMeans(n_init=&#x27;auto&#x27;)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" checked><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">KMeans</label><div class=\"sk-toggleable__content\"><pre>KMeans(n_init=&#x27;auto&#x27;)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "KMeans(n_init='auto')"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "k_means_model.fit(features_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "ad566559",
   "metadata": {},
   "outputs": [],
   "source": [
    "features_ds_group = k_means_model.predict(features_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "a08e554a",
   "metadata": {},
   "outputs": [],
   "source": [
    "features_ds_group = features_ds_group.reshape(features_ds_group.size,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "db150603",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1036, 1)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features_ds_group.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "38b8045a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1036, 20)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features_ds.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "dadec027",
   "metadata": {},
   "outputs": [],
   "source": [
    "features_ds_K_Means = np.concatenate((features_ds, features_ds_group), axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "349f3822",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "      <th>14</th>\n",
       "      <th>15</th>\n",
       "      <th>16</th>\n",
       "      <th>17</th>\n",
       "      <th>18</th>\n",
       "      <th>19</th>\n",
       "      <th>20</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.587192</td>\n",
       "      <td>-1.133756</td>\n",
       "      <td>0.033144</td>\n",
       "      <td>0.185949</td>\n",
       "      <td>0.301294</td>\n",
       "      <td>-0.327468</td>\n",
       "      <td>-0.445468</td>\n",
       "      <td>-0.733264</td>\n",
       "      <td>-0.279039</td>\n",
       "      <td>-0.182255</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.626633</td>\n",
       "      <td>-0.957988</td>\n",
       "      <td>0.261620</td>\n",
       "      <td>-0.450921</td>\n",
       "      <td>0.951292</td>\n",
       "      <td>0.868568</td>\n",
       "      <td>0.966943</td>\n",
       "      <td>0.093340</td>\n",
       "      <td>0.117132</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.800431</td>\n",
       "      <td>-2.971895</td>\n",
       "      <td>-1.208106</td>\n",
       "      <td>-1.071918</td>\n",
       "      <td>-1.019095</td>\n",
       "      <td>-0.751425</td>\n",
       "      <td>-0.763925</td>\n",
       "      <td>-1.119656</td>\n",
       "      <td>-0.712215</td>\n",
       "      <td>-0.392760</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.626633</td>\n",
       "      <td>-1.512201</td>\n",
       "      <td>-0.986292</td>\n",
       "      <td>-1.233555</td>\n",
       "      <td>-0.139663</td>\n",
       "      <td>0.061195</td>\n",
       "      <td>-0.216463</td>\n",
       "      <td>0.320016</td>\n",
       "      <td>0.553415</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.800431</td>\n",
       "      <td>-0.254646</td>\n",
       "      <td>-0.369782</td>\n",
       "      <td>-0.382120</td>\n",
       "      <td>-0.349286</td>\n",
       "      <td>-0.900383</td>\n",
       "      <td>-1.022133</td>\n",
       "      <td>-0.852154</td>\n",
       "      <td>-0.656680</td>\n",
       "      <td>-0.133676</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.652456</td>\n",
       "      <td>-0.823179</td>\n",
       "      <td>-0.291252</td>\n",
       "      <td>-0.294395</td>\n",
       "      <td>1.907283</td>\n",
       "      <td>-0.296166</td>\n",
       "      <td>-0.216463</td>\n",
       "      <td>-0.677359</td>\n",
       "      <td>-0.069846</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.587192</td>\n",
       "      <td>-3.051814</td>\n",
       "      <td>-1.484103</td>\n",
       "      <td>-1.240986</td>\n",
       "      <td>-1.272277</td>\n",
       "      <td>-1.118090</td>\n",
       "      <td>-1.177058</td>\n",
       "      <td>-1.045350</td>\n",
       "      <td>-0.939910</td>\n",
       "      <td>-0.838061</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.574986</td>\n",
       "      <td>-1.826754</td>\n",
       "      <td>-1.210074</td>\n",
       "      <td>-0.333526</td>\n",
       "      <td>0.658871</td>\n",
       "      <td>-0.653528</td>\n",
       "      <td>-0.764336</td>\n",
       "      <td>-0.178671</td>\n",
       "      <td>-0.506129</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.800431</td>\n",
       "      <td>-0.893999</td>\n",
       "      <td>-0.322553</td>\n",
       "      <td>0.375305</td>\n",
       "      <td>-0.153792</td>\n",
       "      <td>-0.384760</td>\n",
       "      <td>-0.445468</td>\n",
       "      <td>0.024659</td>\n",
       "      <td>0.381833</td>\n",
       "      <td>-0.449435</td>\n",
       "      <td>...</td>\n",
       "      <td>0.354643</td>\n",
       "      <td>-0.883094</td>\n",
       "      <td>0.208966</td>\n",
       "      <td>3.188325</td>\n",
       "      <td>0.445179</td>\n",
       "      <td>0.127374</td>\n",
       "      <td>0.747794</td>\n",
       "      <td>0.909374</td>\n",
       "      <td>-0.319151</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1031</th>\n",
       "      <td>0.013671</td>\n",
       "      <td>-0.414484</td>\n",
       "      <td>-1.206630</td>\n",
       "      <td>-0.916375</td>\n",
       "      <td>-0.999866</td>\n",
       "      <td>-1.118090</td>\n",
       "      <td>-1.125417</td>\n",
       "      <td>-0.109092</td>\n",
       "      <td>-0.329021</td>\n",
       "      <td>-0.757097</td>\n",
       "      <td>...</td>\n",
       "      <td>0.509581</td>\n",
       "      <td>-0.119179</td>\n",
       "      <td>-1.025783</td>\n",
       "      <td>0.644766</td>\n",
       "      <td>-0.938197</td>\n",
       "      <td>-1.381486</td>\n",
       "      <td>-1.114974</td>\n",
       "      <td>-0.224007</td>\n",
       "      <td>-0.755434</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1032</th>\n",
       "      <td>0.800431</td>\n",
       "      <td>-1.213675</td>\n",
       "      <td>-1.479675</td>\n",
       "      <td>-0.909612</td>\n",
       "      <td>-0.983842</td>\n",
       "      <td>-0.224344</td>\n",
       "      <td>-0.204473</td>\n",
       "      <td>-0.450901</td>\n",
       "      <td>-0.723322</td>\n",
       "      <td>-0.910929</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.729925</td>\n",
       "      <td>-1.242584</td>\n",
       "      <td>-0.815165</td>\n",
       "      <td>0.527371</td>\n",
       "      <td>-0.139663</td>\n",
       "      <td>-1.566785</td>\n",
       "      <td>-0.632846</td>\n",
       "      <td>-0.541353</td>\n",
       "      <td>-0.942412</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1033</th>\n",
       "      <td>0.800431</td>\n",
       "      <td>0.944140</td>\n",
       "      <td>0.375558</td>\n",
       "      <td>0.091271</td>\n",
       "      <td>0.185920</td>\n",
       "      <td>-0.178510</td>\n",
       "      <td>-0.299150</td>\n",
       "      <td>0.039520</td>\n",
       "      <td>0.054174</td>\n",
       "      <td>0.360203</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.187641</td>\n",
       "      <td>0.345161</td>\n",
       "      <td>-0.025347</td>\n",
       "      <td>-0.411790</td>\n",
       "      <td>0.883810</td>\n",
       "      <td>0.061195</td>\n",
       "      <td>-0.260292</td>\n",
       "      <td>-0.178671</td>\n",
       "      <td>0.179458</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1034</th>\n",
       "      <td>0.013671</td>\n",
       "      <td>-0.574323</td>\n",
       "      <td>-0.139539</td>\n",
       "      <td>-0.287442</td>\n",
       "      <td>-0.054442</td>\n",
       "      <td>-0.212885</td>\n",
       "      <td>-0.075369</td>\n",
       "      <td>-0.272566</td>\n",
       "      <td>-0.523395</td>\n",
       "      <td>1.736588</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.549163</td>\n",
       "      <td>0.719630</td>\n",
       "      <td>-0.328110</td>\n",
       "      <td>-1.311818</td>\n",
       "      <td>-0.836975</td>\n",
       "      <td>0.206787</td>\n",
       "      <td>-0.150718</td>\n",
       "      <td>-0.450683</td>\n",
       "      <td>2.360873</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1035</th>\n",
       "      <td>0.800431</td>\n",
       "      <td>-0.334565</td>\n",
       "      <td>-0.446530</td>\n",
       "      <td>-0.280679</td>\n",
       "      <td>-0.140972</td>\n",
       "      <td>-0.258719</td>\n",
       "      <td>-0.213080</td>\n",
       "      <td>0.633970</td>\n",
       "      <td>0.670617</td>\n",
       "      <td>-0.797579</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.471694</td>\n",
       "      <td>0.300225</td>\n",
       "      <td>-0.333376</td>\n",
       "      <td>-0.842238</td>\n",
       "      <td>-0.319615</td>\n",
       "      <td>-0.362344</td>\n",
       "      <td>-0.238378</td>\n",
       "      <td>1.000044</td>\n",
       "      <td>-0.817760</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1036 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            0         1         2         3         4         5         6   \\\n",
       "0     1.587192 -1.133756  0.033144  0.185949  0.301294 -0.327468 -0.445468   \n",
       "1     0.800431 -2.971895 -1.208106 -1.071918 -1.019095 -0.751425 -0.763925   \n",
       "2     0.800431 -0.254646 -0.369782 -0.382120 -0.349286 -0.900383 -1.022133   \n",
       "3     1.587192 -3.051814 -1.484103 -1.240986 -1.272277 -1.118090 -1.177058   \n",
       "4     0.800431 -0.893999 -0.322553  0.375305 -0.153792 -0.384760 -0.445468   \n",
       "...        ...       ...       ...       ...       ...       ...       ...   \n",
       "1031  0.013671 -0.414484 -1.206630 -0.916375 -0.999866 -1.118090 -1.125417   \n",
       "1032  0.800431 -1.213675 -1.479675 -0.909612 -0.983842 -0.224344 -0.204473   \n",
       "1033  0.800431  0.944140  0.375558  0.091271  0.185920 -0.178510 -0.299150   \n",
       "1034  0.013671 -0.574323 -0.139539 -0.287442 -0.054442 -0.212885 -0.075369   \n",
       "1035  0.800431 -0.334565 -0.446530 -0.280679 -0.140972 -0.258719 -0.213080   \n",
       "\n",
       "            7         8         9   ...        11        12        13  \\\n",
       "0    -0.733264 -0.279039 -0.182255  ... -0.626633 -0.957988  0.261620   \n",
       "1    -1.119656 -0.712215 -0.392760  ... -0.626633 -1.512201 -0.986292   \n",
       "2    -0.852154 -0.656680 -0.133676  ... -0.652456 -0.823179 -0.291252   \n",
       "3    -1.045350 -0.939910 -0.838061  ... -0.574986 -1.826754 -1.210074   \n",
       "4     0.024659  0.381833 -0.449435  ...  0.354643 -0.883094  0.208966   \n",
       "...        ...       ...       ...  ...       ...       ...       ...   \n",
       "1031 -0.109092 -0.329021 -0.757097  ...  0.509581 -0.119179 -1.025783   \n",
       "1032 -0.450901 -0.723322 -0.910929  ... -0.729925 -1.242584 -0.815165   \n",
       "1033  0.039520  0.054174  0.360203  ... -0.187641  0.345161 -0.025347   \n",
       "1034 -0.272566 -0.523395  1.736588  ... -0.549163  0.719630 -0.328110   \n",
       "1035  0.633970  0.670617 -0.797579  ... -0.471694  0.300225 -0.333376   \n",
       "\n",
       "            14        15        16        17        18        19   20  \n",
       "0    -0.450921  0.951292  0.868568  0.966943  0.093340  0.117132  1.0  \n",
       "1    -1.233555 -0.139663  0.061195 -0.216463  0.320016  0.553415  0.0  \n",
       "2    -0.294395  1.907283 -0.296166 -0.216463 -0.677359 -0.069846  0.0  \n",
       "3    -0.333526  0.658871 -0.653528 -0.764336 -0.178671 -0.506129  0.0  \n",
       "4     3.188325  0.445179  0.127374  0.747794  0.909374 -0.319151  5.0  \n",
       "...        ...       ...       ...       ...       ...       ...  ...  \n",
       "1031  0.644766 -0.938197 -1.381486 -1.114974 -0.224007 -0.755434  3.0  \n",
       "1032  0.527371 -0.139663 -1.566785 -0.632846 -0.541353 -0.942412  3.0  \n",
       "1033 -0.411790  0.883810  0.061195 -0.260292 -0.178671  0.179458  1.0  \n",
       "1034 -1.311818 -0.836975  0.206787 -0.150718 -0.450683  2.360873  1.0  \n",
       "1035 -0.842238 -0.319615 -0.362344 -0.238378  1.000044 -0.817760  5.0  \n",
       "\n",
       "[1036 rows x 21 columns]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(features_ds_K_Means)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "52d80405",
   "metadata": {},
   "outputs": [],
   "source": [
    "features_ds_pca_kmeans = np.concatenate((features_ds_pca, features_ds_group), axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "c9e38df2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "      <th>14</th>\n",
       "      <th>15</th>\n",
       "      <th>16</th>\n",
       "      <th>17</th>\n",
       "      <th>18</th>\n",
       "      <th>19</th>\n",
       "      <th>20</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.292134</td>\n",
       "      <td>-1.257798</td>\n",
       "      <td>-0.707501</td>\n",
       "      <td>-1.869496</td>\n",
       "      <td>1.177831</td>\n",
       "      <td>0.822886</td>\n",
       "      <td>0.089581</td>\n",
       "      <td>-0.574167</td>\n",
       "      <td>0.762674</td>\n",
       "      <td>0.344767</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.312725</td>\n",
       "      <td>0.262175</td>\n",
       "      <td>0.281941</td>\n",
       "      <td>0.023277</td>\n",
       "      <td>-0.140330</td>\n",
       "      <td>0.026398</td>\n",
       "      <td>-0.086339</td>\n",
       "      <td>-0.027676</td>\n",
       "      <td>-0.024713</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-3.327180</td>\n",
       "      <td>-0.757063</td>\n",
       "      <td>-1.204306</td>\n",
       "      <td>-0.415835</td>\n",
       "      <td>2.399911</td>\n",
       "      <td>1.717979</td>\n",
       "      <td>-0.156369</td>\n",
       "      <td>-0.177034</td>\n",
       "      <td>-0.333082</td>\n",
       "      <td>-0.166262</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.175745</td>\n",
       "      <td>0.384300</td>\n",
       "      <td>0.161141</td>\n",
       "      <td>0.093361</td>\n",
       "      <td>0.114670</td>\n",
       "      <td>-0.033822</td>\n",
       "      <td>0.139177</td>\n",
       "      <td>0.097603</td>\n",
       "      <td>0.020054</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-2.015606</td>\n",
       "      <td>-1.362153</td>\n",
       "      <td>-0.405446</td>\n",
       "      <td>-1.433654</td>\n",
       "      <td>-0.467715</td>\n",
       "      <td>0.061849</td>\n",
       "      <td>-0.941400</td>\n",
       "      <td>-0.417769</td>\n",
       "      <td>0.592103</td>\n",
       "      <td>-0.012417</td>\n",
       "      <td>...</td>\n",
       "      <td>0.058895</td>\n",
       "      <td>0.036770</td>\n",
       "      <td>0.066277</td>\n",
       "      <td>0.038942</td>\n",
       "      <td>-0.115642</td>\n",
       "      <td>0.097798</td>\n",
       "      <td>-0.025997</td>\n",
       "      <td>0.074460</td>\n",
       "      <td>-0.040713</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-4.596894</td>\n",
       "      <td>-0.145407</td>\n",
       "      <td>-0.969570</td>\n",
       "      <td>-1.644120</td>\n",
       "      <td>1.998151</td>\n",
       "      <td>1.010000</td>\n",
       "      <td>-0.636268</td>\n",
       "      <td>-0.196166</td>\n",
       "      <td>-0.066107</td>\n",
       "      <td>0.347687</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.046553</td>\n",
       "      <td>0.124933</td>\n",
       "      <td>-0.300156</td>\n",
       "      <td>-0.063901</td>\n",
       "      <td>0.008944</td>\n",
       "      <td>0.077846</td>\n",
       "      <td>0.047546</td>\n",
       "      <td>0.057027</td>\n",
       "      <td>-0.015374</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.049892</td>\n",
       "      <td>1.643681</td>\n",
       "      <td>-0.343754</td>\n",
       "      <td>-1.483563</td>\n",
       "      <td>1.923791</td>\n",
       "      <td>-1.813028</td>\n",
       "      <td>-1.181992</td>\n",
       "      <td>-0.583150</td>\n",
       "      <td>1.041105</td>\n",
       "      <td>0.060921</td>\n",
       "      <td>...</td>\n",
       "      <td>0.043405</td>\n",
       "      <td>0.367791</td>\n",
       "      <td>0.211550</td>\n",
       "      <td>-0.012893</td>\n",
       "      <td>-0.105319</td>\n",
       "      <td>0.023094</td>\n",
       "      <td>0.008346</td>\n",
       "      <td>-0.004242</td>\n",
       "      <td>0.040277</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1031</th>\n",
       "      <td>-3.179523</td>\n",
       "      <td>1.807039</td>\n",
       "      <td>0.546411</td>\n",
       "      <td>0.404087</td>\n",
       "      <td>0.054136</td>\n",
       "      <td>-0.250871</td>\n",
       "      <td>-0.225722</td>\n",
       "      <td>0.239025</td>\n",
       "      <td>0.294486</td>\n",
       "      <td>-0.461221</td>\n",
       "      <td>...</td>\n",
       "      <td>0.583488</td>\n",
       "      <td>-0.024619</td>\n",
       "      <td>-0.018336</td>\n",
       "      <td>-0.049239</td>\n",
       "      <td>0.009372</td>\n",
       "      <td>-0.107070</td>\n",
       "      <td>-0.003852</td>\n",
       "      <td>0.028336</td>\n",
       "      <td>0.000166</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1032</th>\n",
       "      <td>-3.357408</td>\n",
       "      <td>0.636947</td>\n",
       "      <td>-0.259547</td>\n",
       "      <td>-1.023044</td>\n",
       "      <td>0.701822</td>\n",
       "      <td>-0.669717</td>\n",
       "      <td>0.327507</td>\n",
       "      <td>0.246211</td>\n",
       "      <td>-0.920763</td>\n",
       "      <td>0.521672</td>\n",
       "      <td>...</td>\n",
       "      <td>0.217559</td>\n",
       "      <td>0.125018</td>\n",
       "      <td>-0.079194</td>\n",
       "      <td>-0.044589</td>\n",
       "      <td>-0.069223</td>\n",
       "      <td>0.037971</td>\n",
       "      <td>-0.083109</td>\n",
       "      <td>0.034924</td>\n",
       "      <td>0.066822</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1033</th>\n",
       "      <td>0.475405</td>\n",
       "      <td>-0.951874</td>\n",
       "      <td>1.057638</td>\n",
       "      <td>-0.566269</td>\n",
       "      <td>-0.912363</td>\n",
       "      <td>0.382992</td>\n",
       "      <td>-0.458896</td>\n",
       "      <td>-0.299393</td>\n",
       "      <td>0.093178</td>\n",
       "      <td>0.560132</td>\n",
       "      <td>...</td>\n",
       "      <td>0.032868</td>\n",
       "      <td>0.021519</td>\n",
       "      <td>-0.021933</td>\n",
       "      <td>-0.029983</td>\n",
       "      <td>0.072934</td>\n",
       "      <td>0.009080</td>\n",
       "      <td>-0.007498</td>\n",
       "      <td>-0.040534</td>\n",
       "      <td>0.011361</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1034</th>\n",
       "      <td>0.281951</td>\n",
       "      <td>-2.579041</td>\n",
       "      <td>1.511082</td>\n",
       "      <td>1.600706</td>\n",
       "      <td>1.212078</td>\n",
       "      <td>1.070659</td>\n",
       "      <td>-0.014405</td>\n",
       "      <td>0.085989</td>\n",
       "      <td>-0.765637</td>\n",
       "      <td>0.081333</td>\n",
       "      <td>...</td>\n",
       "      <td>0.645499</td>\n",
       "      <td>-0.155930</td>\n",
       "      <td>0.169430</td>\n",
       "      <td>0.200307</td>\n",
       "      <td>0.137249</td>\n",
       "      <td>-0.056131</td>\n",
       "      <td>-0.002074</td>\n",
       "      <td>0.065931</td>\n",
       "      <td>0.025794</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1035</th>\n",
       "      <td>-0.588314</td>\n",
       "      <td>1.231915</td>\n",
       "      <td>0.114124</td>\n",
       "      <td>-0.614644</td>\n",
       "      <td>-0.172459</td>\n",
       "      <td>1.319147</td>\n",
       "      <td>0.441039</td>\n",
       "      <td>-0.920927</td>\n",
       "      <td>-0.673559</td>\n",
       "      <td>0.156526</td>\n",
       "      <td>...</td>\n",
       "      <td>0.288086</td>\n",
       "      <td>0.337843</td>\n",
       "      <td>0.051911</td>\n",
       "      <td>-0.109301</td>\n",
       "      <td>0.051556</td>\n",
       "      <td>-0.002628</td>\n",
       "      <td>-0.001309</td>\n",
       "      <td>0.003644</td>\n",
       "      <td>0.009283</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1036 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            0         1         2         3         4         5         6   \\\n",
       "0    -0.292134 -1.257798 -0.707501 -1.869496  1.177831  0.822886  0.089581   \n",
       "1    -3.327180 -0.757063 -1.204306 -0.415835  2.399911  1.717979 -0.156369   \n",
       "2    -2.015606 -1.362153 -0.405446 -1.433654 -0.467715  0.061849 -0.941400   \n",
       "3    -4.596894 -0.145407 -0.969570 -1.644120  1.998151  1.010000 -0.636268   \n",
       "4    -0.049892  1.643681 -0.343754 -1.483563  1.923791 -1.813028 -1.181992   \n",
       "...        ...       ...       ...       ...       ...       ...       ...   \n",
       "1031 -3.179523  1.807039  0.546411  0.404087  0.054136 -0.250871 -0.225722   \n",
       "1032 -3.357408  0.636947 -0.259547 -1.023044  0.701822 -0.669717  0.327507   \n",
       "1033  0.475405 -0.951874  1.057638 -0.566269 -0.912363  0.382992 -0.458896   \n",
       "1034  0.281951 -2.579041  1.511082  1.600706  1.212078  1.070659 -0.014405   \n",
       "1035 -0.588314  1.231915  0.114124 -0.614644 -0.172459  1.319147  0.441039   \n",
       "\n",
       "            7         8         9   ...        11        12        13  \\\n",
       "0    -0.574167  0.762674  0.344767  ... -0.312725  0.262175  0.281941   \n",
       "1    -0.177034 -0.333082 -0.166262  ... -0.175745  0.384300  0.161141   \n",
       "2    -0.417769  0.592103 -0.012417  ...  0.058895  0.036770  0.066277   \n",
       "3    -0.196166 -0.066107  0.347687  ... -0.046553  0.124933 -0.300156   \n",
       "4    -0.583150  1.041105  0.060921  ...  0.043405  0.367791  0.211550   \n",
       "...        ...       ...       ...  ...       ...       ...       ...   \n",
       "1031  0.239025  0.294486 -0.461221  ...  0.583488 -0.024619 -0.018336   \n",
       "1032  0.246211 -0.920763  0.521672  ...  0.217559  0.125018 -0.079194   \n",
       "1033 -0.299393  0.093178  0.560132  ...  0.032868  0.021519 -0.021933   \n",
       "1034  0.085989 -0.765637  0.081333  ...  0.645499 -0.155930  0.169430   \n",
       "1035 -0.920927 -0.673559  0.156526  ...  0.288086  0.337843  0.051911   \n",
       "\n",
       "            14        15        16        17        18        19   20  \n",
       "0     0.023277 -0.140330  0.026398 -0.086339 -0.027676 -0.024713  1.0  \n",
       "1     0.093361  0.114670 -0.033822  0.139177  0.097603  0.020054  0.0  \n",
       "2     0.038942 -0.115642  0.097798 -0.025997  0.074460 -0.040713  0.0  \n",
       "3    -0.063901  0.008944  0.077846  0.047546  0.057027 -0.015374  0.0  \n",
       "4    -0.012893 -0.105319  0.023094  0.008346 -0.004242  0.040277  5.0  \n",
       "...        ...       ...       ...       ...       ...       ...  ...  \n",
       "1031 -0.049239  0.009372 -0.107070 -0.003852  0.028336  0.000166  3.0  \n",
       "1032 -0.044589 -0.069223  0.037971 -0.083109  0.034924  0.066822  3.0  \n",
       "1033 -0.029983  0.072934  0.009080 -0.007498 -0.040534  0.011361  1.0  \n",
       "1034  0.200307  0.137249 -0.056131 -0.002074  0.065931  0.025794  1.0  \n",
       "1035 -0.109301  0.051556 -0.002628 -0.001309  0.003644  0.009283  5.0  \n",
       "\n",
       "[1036 rows x 21 columns]"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(features_ds_pca_kmeans)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "136c23e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "features_ds_all = np.concatenate((features_ds, features_ds_pca, features_ds_group), axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "3688d478",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>31</th>\n",
       "      <th>32</th>\n",
       "      <th>33</th>\n",
       "      <th>34</th>\n",
       "      <th>35</th>\n",
       "      <th>36</th>\n",
       "      <th>37</th>\n",
       "      <th>38</th>\n",
       "      <th>39</th>\n",
       "      <th>40</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.587192</td>\n",
       "      <td>-1.133756</td>\n",
       "      <td>0.033144</td>\n",
       "      <td>0.185949</td>\n",
       "      <td>0.301294</td>\n",
       "      <td>-0.327468</td>\n",
       "      <td>-0.445468</td>\n",
       "      <td>-0.733264</td>\n",
       "      <td>-0.279039</td>\n",
       "      <td>-0.182255</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.312725</td>\n",
       "      <td>0.262175</td>\n",
       "      <td>0.281941</td>\n",
       "      <td>0.023277</td>\n",
       "      <td>-0.140330</td>\n",
       "      <td>0.026398</td>\n",
       "      <td>-0.086339</td>\n",
       "      <td>-0.027676</td>\n",
       "      <td>-0.024713</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.800431</td>\n",
       "      <td>-2.971895</td>\n",
       "      <td>-1.208106</td>\n",
       "      <td>-1.071918</td>\n",
       "      <td>-1.019095</td>\n",
       "      <td>-0.751425</td>\n",
       "      <td>-0.763925</td>\n",
       "      <td>-1.119656</td>\n",
       "      <td>-0.712215</td>\n",
       "      <td>-0.392760</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.175745</td>\n",
       "      <td>0.384300</td>\n",
       "      <td>0.161141</td>\n",
       "      <td>0.093361</td>\n",
       "      <td>0.114670</td>\n",
       "      <td>-0.033822</td>\n",
       "      <td>0.139177</td>\n",
       "      <td>0.097603</td>\n",
       "      <td>0.020054</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.800431</td>\n",
       "      <td>-0.254646</td>\n",
       "      <td>-0.369782</td>\n",
       "      <td>-0.382120</td>\n",
       "      <td>-0.349286</td>\n",
       "      <td>-0.900383</td>\n",
       "      <td>-1.022133</td>\n",
       "      <td>-0.852154</td>\n",
       "      <td>-0.656680</td>\n",
       "      <td>-0.133676</td>\n",
       "      <td>...</td>\n",
       "      <td>0.058895</td>\n",
       "      <td>0.036770</td>\n",
       "      <td>0.066277</td>\n",
       "      <td>0.038942</td>\n",
       "      <td>-0.115642</td>\n",
       "      <td>0.097798</td>\n",
       "      <td>-0.025997</td>\n",
       "      <td>0.074460</td>\n",
       "      <td>-0.040713</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.587192</td>\n",
       "      <td>-3.051814</td>\n",
       "      <td>-1.484103</td>\n",
       "      <td>-1.240986</td>\n",
       "      <td>-1.272277</td>\n",
       "      <td>-1.118090</td>\n",
       "      <td>-1.177058</td>\n",
       "      <td>-1.045350</td>\n",
       "      <td>-0.939910</td>\n",
       "      <td>-0.838061</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.046553</td>\n",
       "      <td>0.124933</td>\n",
       "      <td>-0.300156</td>\n",
       "      <td>-0.063901</td>\n",
       "      <td>0.008944</td>\n",
       "      <td>0.077846</td>\n",
       "      <td>0.047546</td>\n",
       "      <td>0.057027</td>\n",
       "      <td>-0.015374</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.800431</td>\n",
       "      <td>-0.893999</td>\n",
       "      <td>-0.322553</td>\n",
       "      <td>0.375305</td>\n",
       "      <td>-0.153792</td>\n",
       "      <td>-0.384760</td>\n",
       "      <td>-0.445468</td>\n",
       "      <td>0.024659</td>\n",
       "      <td>0.381833</td>\n",
       "      <td>-0.449435</td>\n",
       "      <td>...</td>\n",
       "      <td>0.043405</td>\n",
       "      <td>0.367791</td>\n",
       "      <td>0.211550</td>\n",
       "      <td>-0.012893</td>\n",
       "      <td>-0.105319</td>\n",
       "      <td>0.023094</td>\n",
       "      <td>0.008346</td>\n",
       "      <td>-0.004242</td>\n",
       "      <td>0.040277</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1031</th>\n",
       "      <td>0.013671</td>\n",
       "      <td>-0.414484</td>\n",
       "      <td>-1.206630</td>\n",
       "      <td>-0.916375</td>\n",
       "      <td>-0.999866</td>\n",
       "      <td>-1.118090</td>\n",
       "      <td>-1.125417</td>\n",
       "      <td>-0.109092</td>\n",
       "      <td>-0.329021</td>\n",
       "      <td>-0.757097</td>\n",
       "      <td>...</td>\n",
       "      <td>0.583488</td>\n",
       "      <td>-0.024619</td>\n",
       "      <td>-0.018336</td>\n",
       "      <td>-0.049239</td>\n",
       "      <td>0.009372</td>\n",
       "      <td>-0.107070</td>\n",
       "      <td>-0.003852</td>\n",
       "      <td>0.028336</td>\n",
       "      <td>0.000166</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1032</th>\n",
       "      <td>0.800431</td>\n",
       "      <td>-1.213675</td>\n",
       "      <td>-1.479675</td>\n",
       "      <td>-0.909612</td>\n",
       "      <td>-0.983842</td>\n",
       "      <td>-0.224344</td>\n",
       "      <td>-0.204473</td>\n",
       "      <td>-0.450901</td>\n",
       "      <td>-0.723322</td>\n",
       "      <td>-0.910929</td>\n",
       "      <td>...</td>\n",
       "      <td>0.217559</td>\n",
       "      <td>0.125018</td>\n",
       "      <td>-0.079194</td>\n",
       "      <td>-0.044589</td>\n",
       "      <td>-0.069223</td>\n",
       "      <td>0.037971</td>\n",
       "      <td>-0.083109</td>\n",
       "      <td>0.034924</td>\n",
       "      <td>0.066822</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1033</th>\n",
       "      <td>0.800431</td>\n",
       "      <td>0.944140</td>\n",
       "      <td>0.375558</td>\n",
       "      <td>0.091271</td>\n",
       "      <td>0.185920</td>\n",
       "      <td>-0.178510</td>\n",
       "      <td>-0.299150</td>\n",
       "      <td>0.039520</td>\n",
       "      <td>0.054174</td>\n",
       "      <td>0.360203</td>\n",
       "      <td>...</td>\n",
       "      <td>0.032868</td>\n",
       "      <td>0.021519</td>\n",
       "      <td>-0.021933</td>\n",
       "      <td>-0.029983</td>\n",
       "      <td>0.072934</td>\n",
       "      <td>0.009080</td>\n",
       "      <td>-0.007498</td>\n",
       "      <td>-0.040534</td>\n",
       "      <td>0.011361</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1034</th>\n",
       "      <td>0.013671</td>\n",
       "      <td>-0.574323</td>\n",
       "      <td>-0.139539</td>\n",
       "      <td>-0.287442</td>\n",
       "      <td>-0.054442</td>\n",
       "      <td>-0.212885</td>\n",
       "      <td>-0.075369</td>\n",
       "      <td>-0.272566</td>\n",
       "      <td>-0.523395</td>\n",
       "      <td>1.736588</td>\n",
       "      <td>...</td>\n",
       "      <td>0.645499</td>\n",
       "      <td>-0.155930</td>\n",
       "      <td>0.169430</td>\n",
       "      <td>0.200307</td>\n",
       "      <td>0.137249</td>\n",
       "      <td>-0.056131</td>\n",
       "      <td>-0.002074</td>\n",
       "      <td>0.065931</td>\n",
       "      <td>0.025794</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1035</th>\n",
       "      <td>0.800431</td>\n",
       "      <td>-0.334565</td>\n",
       "      <td>-0.446530</td>\n",
       "      <td>-0.280679</td>\n",
       "      <td>-0.140972</td>\n",
       "      <td>-0.258719</td>\n",
       "      <td>-0.213080</td>\n",
       "      <td>0.633970</td>\n",
       "      <td>0.670617</td>\n",
       "      <td>-0.797579</td>\n",
       "      <td>...</td>\n",
       "      <td>0.288086</td>\n",
       "      <td>0.337843</td>\n",
       "      <td>0.051911</td>\n",
       "      <td>-0.109301</td>\n",
       "      <td>0.051556</td>\n",
       "      <td>-0.002628</td>\n",
       "      <td>-0.001309</td>\n",
       "      <td>0.003644</td>\n",
       "      <td>0.009283</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1036 rows × 41 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            0         1         2         3         4         5         6   \\\n",
       "0     1.587192 -1.133756  0.033144  0.185949  0.301294 -0.327468 -0.445468   \n",
       "1     0.800431 -2.971895 -1.208106 -1.071918 -1.019095 -0.751425 -0.763925   \n",
       "2     0.800431 -0.254646 -0.369782 -0.382120 -0.349286 -0.900383 -1.022133   \n",
       "3     1.587192 -3.051814 -1.484103 -1.240986 -1.272277 -1.118090 -1.177058   \n",
       "4     0.800431 -0.893999 -0.322553  0.375305 -0.153792 -0.384760 -0.445468   \n",
       "...        ...       ...       ...       ...       ...       ...       ...   \n",
       "1031  0.013671 -0.414484 -1.206630 -0.916375 -0.999866 -1.118090 -1.125417   \n",
       "1032  0.800431 -1.213675 -1.479675 -0.909612 -0.983842 -0.224344 -0.204473   \n",
       "1033  0.800431  0.944140  0.375558  0.091271  0.185920 -0.178510 -0.299150   \n",
       "1034  0.013671 -0.574323 -0.139539 -0.287442 -0.054442 -0.212885 -0.075369   \n",
       "1035  0.800431 -0.334565 -0.446530 -0.280679 -0.140972 -0.258719 -0.213080   \n",
       "\n",
       "            7         8         9   ...        31        32        33  \\\n",
       "0    -0.733264 -0.279039 -0.182255  ... -0.312725  0.262175  0.281941   \n",
       "1    -1.119656 -0.712215 -0.392760  ... -0.175745  0.384300  0.161141   \n",
       "2    -0.852154 -0.656680 -0.133676  ...  0.058895  0.036770  0.066277   \n",
       "3    -1.045350 -0.939910 -0.838061  ... -0.046553  0.124933 -0.300156   \n",
       "4     0.024659  0.381833 -0.449435  ...  0.043405  0.367791  0.211550   \n",
       "...        ...       ...       ...  ...       ...       ...       ...   \n",
       "1031 -0.109092 -0.329021 -0.757097  ...  0.583488 -0.024619 -0.018336   \n",
       "1032 -0.450901 -0.723322 -0.910929  ...  0.217559  0.125018 -0.079194   \n",
       "1033  0.039520  0.054174  0.360203  ...  0.032868  0.021519 -0.021933   \n",
       "1034 -0.272566 -0.523395  1.736588  ...  0.645499 -0.155930  0.169430   \n",
       "1035  0.633970  0.670617 -0.797579  ...  0.288086  0.337843  0.051911   \n",
       "\n",
       "            34        35        36        37        38        39   40  \n",
       "0     0.023277 -0.140330  0.026398 -0.086339 -0.027676 -0.024713  1.0  \n",
       "1     0.093361  0.114670 -0.033822  0.139177  0.097603  0.020054  0.0  \n",
       "2     0.038942 -0.115642  0.097798 -0.025997  0.074460 -0.040713  0.0  \n",
       "3    -0.063901  0.008944  0.077846  0.047546  0.057027 -0.015374  0.0  \n",
       "4    -0.012893 -0.105319  0.023094  0.008346 -0.004242  0.040277  5.0  \n",
       "...        ...       ...       ...       ...       ...       ...  ...  \n",
       "1031 -0.049239  0.009372 -0.107070 -0.003852  0.028336  0.000166  3.0  \n",
       "1032 -0.044589 -0.069223  0.037971 -0.083109  0.034924  0.066822  3.0  \n",
       "1033 -0.029983  0.072934  0.009080 -0.007498 -0.040534  0.011361  1.0  \n",
       "1034  0.200307  0.137249 -0.056131 -0.002074  0.065931  0.025794  1.0  \n",
       "1035 -0.109301  0.051556 -0.002628 -0.001309  0.003644  0.009283  5.0  \n",
       "\n",
       "[1036 rows x 41 columns]"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(features_ds_all)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f63cb013",
   "metadata": {},
   "source": [
    "## Preprocessing for Model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "49c185dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocessing(input_sample):\n",
    "    \n",
    "    sample_cluster = k_means_model.predict(input_sample)\n",
    "    sample_pca = pca_model.transform(input_sample)\n",
    "    \n",
    "    sample_label = np.concatenate((sample_pca, sample_cluster), axis=-1)\n",
    "\n",
    "    return sample_label"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cb78913",
   "metadata": {},
   "source": [
    "## Linear Regression Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "243a09e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8648278",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LinearRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c90b1cc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee1e0ade",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b163e12",
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_abs_error = mean_absolute_error(y_test, y_pred)\n",
    "r2 = r2_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d097543",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Mean Absolute Error:\", mean_abs_error)\n",
    "print(\"R-squared:\", r2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
